<!--
    Jinja2 Template for AI Risk Analysis Report
-->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Risk Analysis Report</title>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <style>
/* Base Styles - Reset, Layout, Typography */

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.6;
    color: #1F2937;
    background: #F9FAFB;
}

.container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 20px;
}

header {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    padding: 40px 20px;
    border-radius: 12px;
    margin-bottom: 30px;
    box-shadow: 0 10px 40px rgba(0,0,0,0.1);
}

header h1 {
    font-size: 2.5rem;
    margin-bottom: 10px;
    font-weight: 700;
}

header .subtitle {
    font-size: 1.1rem;
    opacity: 0.95;
    font-weight: 300;
}

.metadata {
    background: rgba(255,255,255,0.2);
    padding: 15px;
    border-radius: 8px;
    margin-top: 20px;
    display: flex;
    gap: 30px;
    flex-wrap: wrap;
}

.metadata-item {
    display: flex;
    align-items: center;
    gap: 8px;
}

.metadata-item strong {
    font-weight: 600;
}

.section {
    background: white;
    padding: 30px;
    border-radius: 12px;
    margin-bottom: 30px;
    box-shadow: 0 4px 20px rgba(0,0,0,0.08);
}

.section h2 {
    font-size: 1.8rem;
    margin-bottom: 20px;
    color: #111827;
    border-bottom: 3px solid #667EEA;
    padding-bottom: 10px;
}

.section h3 {
    font-size: 1.4rem;
    margin-top: 25px;
    margin-bottom: 15px;
    color: #374151;
}

.grid-3 {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 20px;
}

.grid-2 {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 25px;
    margin-bottom: 30px;
}

footer {
    text-align: center;
    padding: 30px;
    color: #6B7280;
    font-size: 0.9rem;
    border-top: 1px solid #E5E7EB;
    margin-top: 50px;
}

@media (max-width: 768px) {
    .grid-3 {
        grid-template-columns: 1fr;
    }
    .grid-2 {
        grid-template-columns: 1fr;
    }
    header h1 {
        font-size: 1.8rem;
    }
}

/* Cards for questionnaire Q&A */
.qa-card {
    background: #F3F4F6;
    border: 2px solid #CBD5E1;
    border-radius: 12px;
    padding: 18px 22px 12px 22px;
    margin-bottom: 18px;
    box-shadow: 0 2px 8px rgba(100,116,139,0.07);
}
/* Components - Cards, Badges, Filters, Tree */

.risk-badge {
    display: inline-block;
    padding: 8px 16px;
    border-radius: 20px;
    font-weight: 600;
    font-size: 1.1rem;
    text-transform: uppercase;
}

/* Metadata description box under header */
.metadata-description {
    margin-top: 10px;
    padding: 10px 12px;
    background: #F8FAFC;
    border: 1px solid #E6EEF6;
    border-radius: 8px;
}
.meta-desc-text {
    margin: 0;
    color: #374151;
    font-size: 0.95rem;
    line-height: 1.4;
}
.meta-desc-text.small {
    font-size: 0.85rem;
    color: #6B7280;
}
.metadata-description a {
    color: #1E40AF;
    text-decoration: underline;
}

/* Executive Summary box style */

.executive-summary p {
    margin: 0;
    color: #000000;
    line-height: 1.6;
    font-size: 1.2em;
}



/* Report header actions: title, download link, source link, taxonomy versions */
.report-meta-actions {
    display: flex;
    flex-direction: column;
    gap: 8px;
    margin-top: 12px;
}
.report-meta-actions .report-title {
    font-size: 1.05rem;
    font-weight: 700;
    color: #0F172A;
}
.report-meta-actions .report-links {
    display: flex;
    gap: 12px;
    align-items: center;
}
.meta-link {
    display: inline-block;
    padding: 8px 14px;
    background: linear-gradient(180deg, #0369A1 0%, #075985 100%);
    color: #FFFFFF;
    border-radius: 10px;
    text-decoration: none;
    font-weight: 600;
    font-size: 0.95rem;
    border: 1px solid rgba(3,105,161,0.12);
    box-shadow: 0 6px 18px rgba(3,105,161,0.08);
    transition: transform 0.12s ease, box-shadow 0.12s ease, opacity 0.12s ease;
}
.meta-link:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 24px rgba(3,105,161,0.12);
    opacity: 0.98;
}
.meta-link.secondary {
    background: #FFFFFF;
    color: #075985;
    border: 1px solid #D1E8F6;
    box-shadow: none;
}
.meta-link.secondary:hover {
    transform: translateY(-2px);
}
.taxonomy-versions {
    margin-top: 6px;
    font-size: 0.9rem;
    color: #374151;
}
.taxonomy-versions .taxonomy-item {
    background: #F3F4F6;
    border: 1px solid #E6E9EE;
    padding: 4px 8px;
    border-radius: 6px;
    margin-right: 6px;
}

.risk-badge.critical {
    background: #DC2626;
    color: white;
}

.risk-badge.high {
    background: #F59E0B;
    color: white;
}

.risk-badge.medium {
    background: #10B981;
    color: white;
}

.risk-badge.low {
    background: #3B82F6;
    color: white;
}

.stat-card {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    padding: 25px;
    border-radius: 12px;
    text-align: center;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.stat-card .value {
    font-size: 3rem;
    font-weight: 700;
    margin-bottom: 10px;
}

.stat-card .label {
    font-size: 1rem;
    opacity: 0.9;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.badge {
    display: inline-block;
    padding: 4px 12px;
    border-radius: 12px;
    font-size: 0.85rem;
    font-weight: 600;
}

.badge-high {
    background: #FEE2E2;
    color: #991B1B;
}

.badge-medium {
    background: #FEF3C7;
    color: #92400E;
}

.badge-low {
    background: #D1FAE5;
    color: #065F46;
}

/* Filters */
.filters-bar {
    margin-bottom: 20px;
    display: flex;
    gap: 15px;
    flex-wrap: wrap;
    padding: 15px;
    background: #F3F4F6;
    border-radius: 8px;
}

.filter-group {
    display: flex;
    align-items: center;
    gap: 8px;
}

.filter-group label {
    font-weight: 600;
    font-size: 0.9rem;
    color: #374151;
}

.filter-group select {
    padding: 8px 12px;
    border: 1px solid #D1D5DB;
    border-radius: 6px;
    font-size: 0.95rem;
    background: white;
    cursor: pointer;
}

/* Hierarchical Tree */
.hierarchy-tree {
    border: 1px solid #E5E7EB;
    border-radius: 8px;
    overflow: hidden;
}

.domain-header {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    padding: 15px 20px;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 12px;
    font-weight: 600;
    font-size: 1.1rem;
    transition: opacity 0.2s;
}

.domain-header:hover {
    opacity: 0.9;
}

.domain-header .toggle-icon {
    font-size: 1rem;
    transition: transform 0.3s;
}

.domain-header.collapsed .toggle-icon {
    transform: rotate(-90deg);
}

.domain-content {
    border-top: 1px solid #E5E7EB;
}

.subdomain-header {
    background: #F3F4F6;
    padding: 12px 20px 12px 40px;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 10px;
    font-weight: 600;
    color: #374151;
    border-bottom: 1px solid #E5E7EB;
    transition: background 0.2s;
}

.subdomain-header:hover {
    background: #E5E7EB;
}

.subdomain-header .toggle-icon {
    font-size: 0.9rem;
    transition: transform 0.3s;
}

.subdomain-header.collapsed .toggle-icon {
    transform: rotate(-90deg);
}

.risk-item {
    padding: 15px 20px 15px 60px;
    border-bottom: 1px solid #F3F4F6;
    transition: background 0.2s;
    cursor: pointer;
}

.risk-item:hover {
    background: #F9FAFB;
}

.risk-item:last-child {
    border-bottom: none;
}

.risk-header {
    display: grid;
    grid-template-columns: 2fr 1fr 1fr 1fr 1fr;
    gap: 15px;
    align-items: center;
}

.risk-title {
    font-weight: 600;
    color: #111827;
    font-size: 0.95rem;
}

.risk-details {
    margin-top: 15px;
    padding: 15px;
    background: #F9FAFB;
    border-left: 4px solid #667EEA;
    border-radius: 4px;
    display: none;
}

.risk-details.expanded {
    display: block;
}

.detail-section {
    margin-bottom: 15px;
}

.detail-section:last-child {
    margin-bottom: 0;
}

.detail-label {
    font-weight: 600;
    color: #111827;
    font-size: 0.9rem;
    margin-bottom: 5px;
    display: block;
}

.detail-text {
    color: #374151;
    line-height: 1.6;
    font-size: 0.9rem;
}

/* Follow-up specific styles: display as separated blocks (no bullets) */
.followups {
    display: block;
}
.followup-item {
    padding: 8px 12px;
    margin-bottom: 8px;
    background: #FFFFFF;
    border: 1px solid #E6E9EE;
    border-radius: 6px;
    /* Align font with main detail-text */
    font-size: 0.9rem;
    line-height: 1.6;
    color: #374151;
    font-family: inherit;
}
.followup-q {
    font-weight: 600;
    color: #111827;
    margin-bottom: 4px;
    font-size: 0.9rem;
    line-height: 1.6;
}
.followup-a {
    color: #374151;
    font-size: 0.9rem;
    line-height: 1.6;
}

/* Answer chips for multiple-choice / checkbox responses */
.answer-chips {
    display: flex;
    gap: 8px;
    flex-wrap: wrap;
    margin-top: 6px;
}
.answer-chip {
    display: inline-flex;
    align-items: center;
    background: white;
    border: 1px solid #E6E9EE;
    padding: 6px 10px;
    border-radius: 999px;
    font-size: 0.9rem;
    line-height: 1.4;
    color: #374151;
    box-shadow: 0 1px 2px rgba(15,23,42,0.04);
}

.causality-grid {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 10px;
    margin-top: 10px;
}

.causality-box {
    background: white;
    padding: 10px;
    border-radius: 6px;
    border-left: 3px solid;
}

.causality-box.entity {
    border-left-color: #3B82F6;
}

.causality-box.timing {
    border-left-color: #10B981;
}

.causality-box.intent {
    border-left-color: #F59E0B;
}

.causality-box-label {
    font-size: 0.75rem;
    font-weight: 600;
    color: #6B7280;
    text-transform: uppercase;
    margin-bottom: 4px;
}

.causality-box-text {
    font-size: 0.85rem;
    color: #374151;
    line-height: 1.4;
}

@media (max-width: 768px) {
    .risk-header {
        grid-template-columns: 1fr;
    }
    .causality-grid {
        grid-template-columns: 1fr;
    }
}

/* Pattern Info Section */
.pattern-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: 15px;
    padding: 10px 0;
}

.info-toggle {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    border: none;
    padding: 10px 20px;
    border-radius: 8px;
    font-size: 0.9rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s ease;
    box-shadow: 0 2px 8px rgba(102, 126, 234, 0.3);
}

.info-toggle:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.5);
}

.pattern-info-box {
    background: linear-gradient(135deg, #F3F4F6 0%, #E5E7EB 100%);
    border: 2px solid #667EEA;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 800px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.pattern-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.pattern-info-box h4 {
    color: #374151;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #667EEA;
    padding-bottom: 10px;
}

.pattern-info-box h5 {
    color: #4B5563;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.pattern-info-box p {
    color: #374151;
    line-height: 1.6;
    margin-bottom: 15px;
}

.pattern-info-box ul {
    margin: 10px 0;
    padding-left: 20px;
}

.pattern-info-box li {
    color: #4B5563;
    line-height: 1.8;
    margin-bottom: 8px;
}

.pattern-category {
    background: white;
    border-left: 4px solid #667EEA;
    padding: 15px;
    margin: 15px 0;
    border-radius: 8px;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);
}

/* Domain Info Section */
.domain-info-box {
    background: linear-gradient(135deg, #EFF6FF 0%, #DBEAFE 100%);
    border: 2px solid #3B82F6;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 800px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.domain-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.domain-info-box h4 {
    color: #1E40AF;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #3B82F6;
    padding-bottom: 10px;
}

.domain-info-box h5 {
    color: #1E40AF;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.domain-info-box p {
    color: #374151;
    line-height: 1.7;
    margin-bottom: 15px;
    text-align: justify;
}

.domain-category {
    background: white;
    border-left: 4px solid #3B82F6;
    padding: 15px;
    margin: 15px 0;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(59, 130, 246, 0.1);
}

.domain-category h5 {
    margin-top: 0;
    color: #1E40AF;
    font-weight: 700;
}

.domain-category p {
    margin-bottom: 15px;
    color: #4B5563;
    line-height: 1.7;
}

/* Subdomain Cards */
.subdomain-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
    gap: 10px;
    margin-top: 15px;
}

.subdomain-card {
    background: linear-gradient(135deg, #EFF6FF 0%, #DBEAFE 100%);
    border: 1px solid #93C5FD;
    border-radius: 8px;
    padding: 10px 12px;
    display: flex;
    align-items: center;
    gap: 10px;
    transition: all 0.2s ease;
}

.subdomain-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 8px rgba(59, 130, 246, 0.2);
    border-color: #3B82F6;
}

.subdomain-id {
    background: #3B82F6;
    color: white;
    font-weight: 700;
    font-size: 0.75rem;
    padding: 4px 8px;
    border-radius: 4px;
    flex-shrink: 0;
    min-width: 32px;
    text-align: center;
}

.subdomain-name {
    color: #1E40AF;
    font-size: 0.85rem;
    line-height: 1.4;
    font-weight: 500;
}

/* Alert Info Section */
.alert-info-box {
    background: linear-gradient(135deg, #FEF2F2 0%, #FEE2E2 100%);
    border: 2px solid #DC2626;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 600px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.alert-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.alert-info-box h4 {
    color: #991B1B;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #DC2626;
    padding-bottom: 10px;
}

.alert-info-box h5 {
    color: #B91C1C;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.alert-info-box p {
    color: #374151;
    line-height: 1.7;
    margin-bottom: 15px;
    text-align: justify;
}

.alert-dimension {
    background: white;
    border-left: 4px solid #DC2626;
    padding: 12px 15px;
    margin: 10px 0;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(220, 38, 38, 0.1);
    color: #4B5563;
    line-height: 1.6;
}

/* Sankey Info Section */
.sankey-info-box {
    background: linear-gradient(135deg, #FFFBEB 0%, #FEF3C7 100%);
    border: 2px solid #F59E0B;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 600px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.sankey-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.sankey-info-box h4 {
    color: #92400E;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #F59E0B;
    padding-bottom: 10px;
}

.sankey-info-box h5 {
    color: #B45309;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.sankey-info-box p {
    color: #374151;
    line-height: 1.7;
    margin-bottom: 15px;
    text-align: justify;
}

.sankey-info-box ul {
    margin: 10px 0;
    padding-left: 0;
    list-style: none;
}

.sankey-info-box li {
    color: #4B5563;
    line-height: 1.8;
    margin-bottom: 8px;
    padding-left: 10px;
}

.sankey-dimension {
    background: white;
    border-left: 4px solid #F59E0B;
    padding: 12px 15px;
    margin: 10px 0;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(245, 158, 11, 0.1);
    color: #4B5563;
    line-height: 1.6;
}

/* Charts - Chart containers and grid */

.chart-container {
    background: white;
    padding: 20px;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    min-height: 400px;
}

.chart-container-large {
    background: white;
    padding: 20px;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    min-height: 500px;
}

    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üõ°Ô∏è AI Risk Analysis Report</h1>
            <h2>Comprehensive Risk Assessment & Mitigation Strategy</h2>
            <div class="report-meta-actions">
                <div class="report-links">
                    <button id="download-zip-btn" class="meta-link secondary" onclick="handleDownloadClick()">Download Report</button>
                    <button id="view-analysis-btn" class="meta-link secondary" onclick="openAnalysisJson()">View Analysis JSON</button>
                    
                    
                    <a class="meta-link secondary" href="https://docs.google.com/presentation/d/1wxg-hZAjGvFHcsfnEp1KAJJo5xvf98MB2v50B5URXZM/edit?slide=id.g32ebda0938f_6_0#slide=id.g32ebda0938f_6_0" target="_blank" rel="noopener">MIT Causal Taxonomy: v0.1</a>
                    <a class="meta-link secondary" href="https://docs.google.com/presentation/d/1wxg-hZAjGvFHcsfnEp1KAJJo5xvf98MB2v50B5URXZM/edit?slide=id.g325f13b19c4_0_0#slide=id.g325f13b19c4_0_0" target="_blank" rel="noopener">MIT Domain Taxonomy: v0.1</a>
                </div>

            </div>
        </header>
            <!-- Embed metadata JSON for client-side zip creation -->
            <script id="report-metadata" type="application/json">{"answered_questions": 24, "executive_summary_text": "An in-depth AI risk analysis reveals a global risk score of 61.47, indicating a high overall risk level for the system, primarily driven by active threats that necessitate immediate mitigation actions. The most critical risk area is \"Malicious actors\" (Domain 4), accounting for 4 high-severity risks, particularly within \"Cyberattacks, weapon development or use, and mass harm\" (Subdomain 4.2) with 2 high risks. Following this are \"AI system safety, failures, \u0026 limitations\" (Domain 7) with 2 high risks, and \"Socioeconomic \u0026 Environmental\" (Domain 6) with 1 high risk.\n\nOut of 34 total risks identified, 11 are classified as high severity, 19 as medium, and 4 as low. Analysis of risk patterns reveals 11 intentional threats and a substantial 91.18% of risks categorized as operational. Notably, 10 malicious human risks and 18 unintended AI failures contribute significantly to the risk profile. An alert indicates 0.0% preventable risks, underscoring the need for robust controls. Furthermore, 55.88% of risks accumulate at a medium level, while high risks are fragmented across 7 distinct domains, suggesting broad exposure. Given these findings, immediate mitigation is recommended to address the identified high-severity risks and systemic vulnerabilities.", "language": "en", "run_id": "23d095a19c9c45c89af5c66b5ffcea63", "timestamp": "2025-12-27T16:04:18.749051", "total_questions": 24}</script>
            <!-- Embed analysis and heuristic JSON so the report can open them in a new tab -->
            <script id="report-analysis" type="application/json">{"1.1": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by biases in the AI system\u0027s training data or its tailoring logic.", "value": "ai"}, "intent": {"rationale": "The unfair or suboptimal outputs are an unexpected outcome, as the system\u0027s goal is to tailor output effectively, not to introduce bias.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI system tailors outputs for users, which occurs after deployment.", "value": "post-deployment"}}, "explanation": "The system tailors output based on user roles (e.g., \u0027developer\u0027, \u0027researcher\u0027, \u0027manager\u0027). If the underlying data used to train this tailoring, or the logic itself, contains biases related to these roles (e.g., assuming certain roles require less complex information, or if certain roles are underrepresented in training data), it could lead to unfair or suboptimal outputs for specific user groups, impacting their productivity or access to relevant information.", "mitigation": "Conduct bias audits on the training data and the tailoring algorithms related to user roles. Implement fairness metrics to ensure equitable performance and output quality across different roles. Allow users to override inferred roles or adjust tailoring preferences. Regularly review user feedback for signs of role-based discrimination.", "severity": "medium", "severity_rationale": "The risk of unfair or suboptimal outputs for specific user groups can impact productivity and access to information, which is a significant but not catastrophic harm.", "title": "Bias in output tailoring based on inferred/provided user roles"}]}, "1.2": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s text generation capabilities, stemming from training data biases or model behaviors.", "value": "ai"}, "intent": {"rationale": "The production of harmful content is an unexpected outcome, as the system\u0027s goal is to generate useful text, not offensive material.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI system generates text for users, which occurs after deployment.", "value": "post-deployment"}}, "explanation": "The system generates text, which carries the inherent risk of producing content that is offensive, discriminatory, hateful, or otherwise toxic, even if unintended. This could stem from biases in training data or unforeseen model behaviors, leading to user exposure to harmful material.", "mitigation": "Implement robust content moderation filters and safety classifiers for generated text. Employ adversarial testing to identify and mitigate potential for toxic output. Integrate human-in-the-loop review for sensitive content. Continuously update and refine safety mechanisms based on user feedback and emerging patterns.", "severity": "medium", "severity_rationale": "The generation of harmful content can lead to user exposure to offensive material, causing reputational damage and user distress, which is a significant concern.", "title": "Generation of harmful or inappropriate text content"}, {"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s code generation capabilities, which may produce flawed or malicious code.", "value": "ai"}, "intent": {"rationale": "The generation of insecure or malicious code is an unexpected outcome, as the system\u0027s goal is to generate functional and secure code.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI system generates code that is subsequently used, which occurs after deployment.", "value": "post-deployment"}}, "explanation": "The system generates code, posing a risk if the generated code contains security vulnerabilities, logical flaws, or even intentionally malicious constructs (e.g., backdoors, insecure dependencies). Such code could be exploited in downstream applications, especially given the system\u0027s use in software development and potentially safety-critical systems.", "mitigation": "Implement static code analysis tools and security linters on generated code. Provide clear warnings and disclaimers about the necessity of human review and security auditing for AI-generated code. Train the model on secure coding practices and filter out known insecure patterns. Integrate security best practices into the model\u0027s training and fine-tuning processes.", "severity": "high", "severity_rationale": "The generation of insecure or malicious code can lead to system exploitation, security vulnerabilities, and potential harm in safety-critical systems, posing a severe threat.", "title": "Generation of insecure or malicious code"}]}, "1.3": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s inherent performance characteristics, likely due to biases in training data or model design.", "value": "ai"}, "intent": {"rationale": "Disparate performance is an unexpected outcome, as the system\u0027s goal is to provide high-quality outputs to all users.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI system provides outputs to different user groups, which occurs after deployment.", "value": "post-deployment"}}, "explanation": "The system acknowledges potential differences in performance or accuracy across various user groups. This could mean that certain groups (e.g., users from specific linguistic backgrounds, with particular technical expertise, or in certain geographical regions) receive lower quality, less accurate, or less relevant outputs compared to others, leading to unequal access to the system\u0027s benefits.", "mitigation": "Conduct thorough fairness evaluations and performance audits across identified user groups (e.g., based on inferred roles, language, or other relevant attributes). Implement group-specific metrics and monitor for performance disparities. Investigate and address root causes of unequal performance, potentially through targeted data augmentation, model fine-tuning, or adaptive output mechanisms. Provide transparency regarding known performance limitations across groups.", "severity": "medium", "severity_rationale": "Unequal access to the system\u0027s benefits and lower quality outputs for certain groups can lead to significant fairness and equity concerns, impacting user experience and trust.", "title": "Disparate performance or accuracy across user groups"}]}, "2.1": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by \u0027sophisticated adversaries or advanced analytical techniques\u0027 (operated by humans) attempting to re-identify or infer information.", "value": "human"}, "intent": {"rationale": "The act of re-identifying individuals or inferring sensitive information by adversaries is a deliberate and intentional action.", "value": "intentional"}, "timing": {"rationale": "The inference of information occurs after the data has been collected and the system is operational, allowing for exploitation.", "value": "post-deployment"}}, "explanation": "Although no personally identifiable information (PII) is directly collected, the system ingests anonymized interaction logs, query parameters, and domain-specific metadata (e.g., technical specifications, project requirements, code snippets). There is a residual risk that sophisticated adversaries or advanced analytical techniques could potentially re-identify individuals or infer sensitive business/project information from these aggregated or seemingly anonymized datasets.", "mitigation": "Implement robust anonymization and de-identification techniques, including k-anonymity or differential privacy where applicable. Regularly audit anonymized datasets for re-identification risks. Ensure strict access controls and encryption for all collected data, including domain-specific metadata. Educate users about the types of information they should avoid including in queries or code snippets if it\u0027s highly sensitive.", "severity": "low", "severity_rationale": "While the risk of re-identification or inference of sensitive information is present, the explanation notes \u0027anonymized\u0027 data and \u0027residual risk,\u0027 suggesting a lower likelihood or impact compared to direct PII breaches.", "title": "Inference of sensitive or confidential information from anonymized data or domain-specific metadata"}]}, "2.2": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by \u0027malicious actors\u0027 performing adversarial attacks like prompt injection or data poisoning.", "value": "human"}, "intent": {"rationale": "Adversarial attacks are deliberate and intentional actions aimed at manipulating or corrupting the AI system.", "value": "intentional"}, "timing": {"rationale": "Data poisoning occurs pre-deployment (during training), while prompt injection occurs post-deployment (during inference), making the timing span both categories.", "value": "other"}}, "explanation": "Relying solely on \u0027basic controls\u0027 might leave the AI system vulnerable to attacks specific to machine learning models, such as prompt injection (manipulating input to elicit undesired outputs), data poisoning (corrupting training data to degrade performance or introduce backdoors), or model inversion (reconstructing training data from model outputs). These attacks can compromise the system\u0027s integrity, confidentiality, or availability.", "mitigation": "Implement robust input validation and sanitization to prevent prompt injection. Employ adversarial training techniques and defensive distillation to improve model robustness against evasion attacks. Implement data provenance tracking and anomaly detection for training data to prevent poisoning. Regularly conduct penetration testing and red-teaming exercises specifically targeting AI-specific vulnerabilities.", "severity": "high", "severity_rationale": "Adversarial attacks can compromise the system\u0027s integrity, confidentiality, or availability, leading to severe operational and security failures.", "title": "Vulnerability to adversarial attacks (e.g., prompt injection, data poisoning)"}, {"causality": {"entity": {"rationale": "The risk is caused by \u0027sophisticated cyberattacks\u0027 carried out by malicious human actors.", "value": "human"}, "intent": {"rationale": "Cyberattacks and attempts at unauthorized access are deliberate and intentional actions.", "value": "intentional"}, "timing": {"rationale": "Unauthorized access and data breaches typically occur after the system is deployed and operational.", "value": "post-deployment"}}, "explanation": "While \u0027basic controls\u0027 like authentication and encryption are present, they might not be sufficient to protect against sophisticated cyberattacks targeting the AI model itself, its infrastructure, or the data it processes. This could lead to unauthorized access to the model, its parameters, or the anonymized interaction logs and domain-specific metadata, potentially compromising system integrity or leading to data exfiltration.", "mitigation": "Augment basic controls with advanced security measures, including multi-factor authentication, granular access controls (RBAC), network segmentation, intrusion detection/prevention systems, and regular security audits. Implement secure software development lifecycle (SSDLC) practices for the AI system. Encrypt data at rest and in transit, and ensure key management best practices.", "severity": "medium", "severity_rationale": "Unauthorized access or data breaches can compromise system integrity and lead to data exfiltration, which are significant security concerns.", "title": "Insufficient protection against unauthorized access or data breaches"}]}, "3.1": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s inherent limitations, such as training data issues, model hallucinations, or misinterpretations.", "value": "ai"}, "intent": {"rationale": "The generation of incorrect information is an unexpected outcome, as the system\u0027s goal is to provide accurate information.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI system produces information for users, which occurs after deployment.", "value": "post-deployment"}}, "explanation": "As the system produces information for a broad audience, there is a significant risk that it may generate content that is factually incorrect, outdated, or misleading. This can stem from limitations in its training data, model hallucinations, or misinterpretations of complex queries, leading users to make incorrect decisions or adopt flawed solutions.", "mitigation": "Implement fact-checking mechanisms, cross-referencing with authoritative sources, and confidence scoring for generated information. Clearly indicate the generative nature of the content and advise users to verify critical information. Incorporate human expert review for high-impact outputs. Continuously update the model with the latest information and refine its ability to distinguish between factual and speculative content.", "severity": "high", "severity_rationale": "The generation of factually incorrect or misleading information can lead users to make incorrect decisions or adopt flawed solutions, which can have severe consequences, especially for a broad audience.", "title": "Generation of factually incorrect or misleading information"}, {"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s underlying biases in its training data or its inherent limitations in presenting a complete view.", "value": "ai"}, "intent": {"rationale": "The generation of biased or incomplete information is an unexpected outcome, as the system\u0027s goal is to provide comprehensive and unbiased information.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI system generates information for users, which occurs after deployment.", "value": "post-deployment"}}, "explanation": "The system might generate information that is biased due to underlying biases in its training data or present an incomplete view of a topic, leading users to form skewed perspectives or overlook critical aspects. This is particularly relevant when providing \u0027explanations of technical concepts\u0027 or \u0027architectural design suggestions.\u0027", "mitigation": "Diversify training data to reduce inherent biases. Implement mechanisms to detect and flag potential biases in generated content. Encourage the system to present multiple perspectives or acknowledge limitations. Provide users with tools to explore alternative viewpoints or sources. Regularly audit outputs for fairness and completeness.", "severity": "medium", "severity_rationale": "The generation of biased or incomplete information can lead to skewed perspectives and overlooked critical aspects, impacting decision-making and understanding, which is a significant concern.", "title": "Generation of biased or incomplete information"}]}, "3.2": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s personalization algorithms inadvertently creating filter bubbles.", "value": "ai"}, "intent": {"rationale": "The creation of filter bubbles is an unexpected outcome of the system\u0027s goal to enhance relevance through personalization.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI system personalizes outputs for users, which occurs after deployment.", "value": "post-deployment"}}, "explanation": "The system personalizes output based on user profiles and interactions. While intended to enhance relevance, this can inadvertently create filter bubbles, where users are primarily exposed to information that aligns with their past interactions or inferred preferences. This limits exposure to diverse viewpoints, potentially reinforcing existing biases and hindering a comprehensive understanding of complex topics.", "mitigation": "Implement features that encourage serendipitous discovery and exposure to diverse perspectives, even within personalized outputs. Provide options for users to adjust or disable personalization. Clearly indicate when content is personalized and offer tools to explore non-personalized or alternative views. Regularly audit personalization algorithms for unintended consequences like excessive content filtering.", "severity": "medium", "severity_rationale": "The creation of filter bubbles can limit exposure to diverse viewpoints and reinforce biases, hindering comprehensive understanding, which is a significant societal and informational risk.", "title": "Creation of filter bubbles or echo chambers"}]}, "4.1": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by \u0027malicious actors\u0027 intentionally exploiting the AI system\u0027s capabilities.", "value": "human"}, "intent": {"rationale": "The generation and dissemination of disinformation by malicious actors is a deliberate and intentional act.", "value": "intentional"}, "timing": {"rationale": "The exploitation occurs after the AI system is deployed and available for use by malicious actors.", "value": "post-deployment"}}, "explanation": "The system\u0027s ability to generate text and information for large groups, combined with its potential for personalization, makes it a powerful tool for malicious actors to create and spread disinformation, propaganda, or misleading narratives efficiently and at scale. This could manipulate public opinion, sow discord, or undermine trust in information sources.", "mitigation": "Implement robust content provenance and watermarking techniques for AI-generated content. Develop and deploy advanced detection mechanisms for AI-generated disinformation. Establish clear use policies prohibiting the generation of misleading content and enforce them rigorously. Collaborate with fact-checking organizations and researchers to identify and counter disinformation campaigns.", "severity": "high", "severity_rationale": "The exploitation for large-scale disinformation can manipulate public opinion, sow discord, and undermine trust, posing a severe societal threat.", "title": "Exploitation for generating and disseminating disinformation at scale"}, {"causality": {"entity": {"rationale": "The risk is caused by \u0027malicious actors\u0027 intentionally exploiting the AI system\u0027s capabilities.", "value": "human"}, "intent": {"rationale": "The act of influencing or manipulating user behavior by malicious actors is a deliberate and intentional act.", "value": "intentional"}, "timing": {"rationale": "The exploitation occurs after the AI system is deployed and available for use by malicious actors.", "value": "post-deployment"}}, "explanation": "While PII is not collected, the system\u0027s ability to tailor outputs based on user roles and interactions, and its capacity to provide information to large groups, could be exploited by malicious actors to subtly influence user behavior, opinions, or decision-making at scale. This could involve nudging users towards specific technical solutions, political views, or commercial products.", "mitigation": "Implement transparency mechanisms that clearly indicate when content is personalized or generated by AI. Provide users with control over personalization settings. Regularly audit the system\u0027s outputs for manipulative patterns or biases. Educate users about the potential for AI-driven influence and critical evaluation of information.", "severity": "medium", "severity_rationale": "Large-scale influence or manipulation can subtly alter user behavior and decision-making, which is a significant ethical and societal concern.", "title": "Exploitation for large-scale influence or manipulation"}]}, "4.2": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by \u0027malicious actors\u0027 intentionally exploiting the AI system\u0027s capabilities.", "value": "human"}, "intent": {"rationale": "The development of malware and cyberattack tools by malicious actors is a deliberate and intentional act.", "value": "intentional"}, "timing": {"rationale": "The exploitation occurs after the AI system is deployed and available for use by malicious actors.", "value": "post-deployment"}}, "explanation": "The system\u0027s capability to generate code, debug assistance, and provide technical specifications could be exploited by malicious actors to develop sophisticated malware, identify vulnerabilities in systems, or craft more effective cyberattack tools. This risk is amplified by its use in \u0027software development\u0027 and potential application in \u0027safety-critical systems.\u0027", "mitigation": "Implement strict content filtering and ethical guidelines to prevent the generation of malicious code or instructions for cyberattacks. Monitor for suspicious queries or usage patterns indicative of malicious intent. Restrict access to certain sensitive capabilities or knowledge. Collaborate with cybersecurity experts to understand and mitigate potential misuse vectors.", "severity": "high", "severity_rationale": "The facilitation of cyberattacks or malware development can lead to severe security breaches, system compromises, and potential harm in safety-critical systems.", "title": "Facilitation of cyberattacks or malware development"}, {"causality": {"entity": {"rationale": "The risk is caused by human actors intentionally adapting or misusing the AI system\u0027s capabilities for harmful purposes.", "value": "human"}, "intent": {"rationale": "The development of harmful autonomous systems or large-scale harm through misuse is a deliberate and intentional act by malicious actors.", "value": "intentional"}, "timing": {"rationale": "The misuse occurs after the AI system is deployed and its capabilities can be leveraged.", "value": "post-deployment"}}, "explanation": "While not directly designed for it, the system\u0027s advanced capabilities in code generation, technical problem-solving, and knowledge synthesis could theoretically be adapted or misused to assist in the development of autonomous systems with harmful intent, or to design systems that could cause large-scale physical or societal harm if not properly controlled. This is particularly concerning given its use in \u0027safety-critical systems.\u0027", "mitigation": "Implement strong ethical use policies and technical safeguards to prevent the system from being used for harmful purposes. Conduct thorough red-teaming and risk assessments specifically focused on misuse for dangerous capabilities. Restrict access to highly sensitive or potentially dangerous functionalities. Engage with policymakers and the AI safety community to develop industry-wide standards and regulations for preventing such misuse.", "severity": "high", "severity_rationale": "The contribution to harmful autonomous systems or large-scale harm represents a severe and potentially catastrophic risk to physical safety and societal well-being.", "title": "Contribution to the development of harmful autonomous systems or large-scale harm"}]}, "4.3": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by \u0027malicious actors\u0027 intentionally exploiting the AI system\u0027s capabilities.", "value": "human"}, "intent": {"rationale": "The creation of fraudulent content or attacks by malicious actors is a deliberate and intentional act.", "value": "intentional"}, "timing": {"rationale": "The exploitation occurs after the AI system is deployed and available for use by malicious actors.", "value": "post-deployment"}}, "explanation": "The system\u0027s ability to generate coherent and contextually relevant text, combined with personalization capabilities, could be exploited by malicious actors to create highly convincing phishing emails, fraudulent messages, or scam narratives. This could lead to financial loss, identity theft, or other forms of harm for individuals or groups.", "mitigation": "Implement content filters to detect and prevent the generation of fraudulent or manipulative content. Educate users about the risks of AI-generated scams and how to identify them. Monitor for patterns of misuse related to fraud. Collaborate with law enforcement and cybersecurity agencies to address emerging threats.", "severity": "high", "severity_rationale": "The facilitation of fraud, scams, or phishing attacks can lead to severe financial loss, identity theft, and other forms of harm for individuals.", "title": "Facilitation of fraud, scams, or phishing attacks"}, {"causality": {"entity": {"rationale": "The risk is caused by human actors intentionally misusing the AI system\u0027s capabilities for manipulation.", "value": "human"}, "intent": {"rationale": "The act of targeted manipulation by malicious actors is a deliberate and intentional act.", "value": "intentional"}, "timing": {"rationale": "The misuse occurs after the AI system is deployed and its personalization capabilities can be leveraged.", "value": "post-deployment"}}, "explanation": "Leveraging its personalization capabilities and understanding of user roles/interactions, the system could be misused to craft highly targeted and persuasive messages designed to manipulate individuals or specific groups into making certain decisions, revealing sensitive information, or acting against their best interests.", "mitigation": "Implement strict ethical guidelines for personalization and content generation. Provide users with transparency regarding how content is tailored. Offer tools for users to report suspicious or manipulative content. Regularly audit the system\u0027s outputs for manipulative language or patterns.", "severity": "medium", "severity_rationale": "Targeted manipulation can lead to individuals acting against their best interests or revealing sensitive information, which is a significant ethical and privacy concern.", "title": "Targeted manipulation of individuals or groups"}]}, "5.1": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by human users making the decision to over-rely on AI outputs without verification.", "value": "human"}, "intent": {"rationale": "Overreliance is an unexpected outcome, often stemming from trust or convenience, rather than a deliberate goal.", "value": "unintentional"}, "timing": {"rationale": "The overreliance manifests when users interact with the deployed AI system and its outputs.", "value": "post-deployment"}}, "explanation": "Given the system\u0027s use in \u0027software development,\u0027 \u0027debugging assistance,\u0027 \u0027architectural design suggestions,\u0027 and \u0027safety-critical systems,\u0027 there is a high risk that users may over-rely on the AI\u0027s outputs without sufficient human verification. This can lead to the adoption of incorrect code, flawed designs, or erroneous technical information, potentially resulting in system failures, security vulnerabilities, or even physical harm in safety-critical contexts.", "mitigation": "Implement clear disclaimers and warnings about the generative nature of the content and the necessity of human review and validation, especially for critical applications. Design the user interface to encourage critical thinking and verification. Integrate human-in-the-loop processes for all high-stakes decisions or code deployments. Provide training to users on the limitations of AI and best practices for its safe integration into workflows.", "severity": "high", "severity_rationale": "Overreliance can lead to system failures, security vulnerabilities, or physical harm in safety-critical contexts, representing a severe risk.", "title": "Overreliance on AI-generated outputs in critical applications"}, {"causality": {"entity": {"rationale": "The risk is caused by human users making decisions to use the system inappropriately due to a lack of understanding.", "value": "human"}, "intent": {"rationale": "Unsafe use is an unexpected outcome, stemming from a lack of user understanding rather than deliberate intent to cause harm.", "value": "unintentional"}, "timing": {"rationale": "The unsafe use manifests when users interact with the deployed AI system.", "value": "post-deployment"}}, "explanation": "Users, particularly those less familiar with AI capabilities and limitations, might use the system in ways it was not intended or in contexts where its accuracy is not guaranteed. For example, applying general code suggestions directly to highly specialized or sensitive systems without understanding potential side effects or incompatibilities.", "mitigation": "Provide comprehensive documentation and tutorials on the system\u0027s capabilities, limitations, and appropriate use cases. Implement guardrails and contextual warnings within the system to guide users away from potentially unsafe applications. Encourage a culture of continuous learning and critical evaluation among users.", "severity": "medium", "severity_rationale": "Unsafe use can lead to unintended side effects or incompatibilities, potentially causing system issues or failures, which is a significant operational risk.", "title": "Unsafe use due to lack of understanding of AI limitations"}]}, "5.2": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s continuous provision of solutions, which subtly influences user behavior.", "value": "ai"}, "intent": {"rationale": "The subtle influence and skill degradation are unexpected outcomes of the system\u0027s goal to provide assistance and solutions.", "value": "unintentional"}, "timing": {"rationale": "The influence and skill degradation occur over time as users interact with the deployed AI system.", "value": "post-deployment"}}, "explanation": "Although the system \u0027only suggests\u0027 and makes \u0027no binding decisions,\u0027 its continuous provision of solutions, code, or explanations can subtly influence user choices and reduce the need for users to engage in deep problem-solving or critical thinking. Over time, this could lead to a degradation of human skills in areas like debugging, architectural design, or complex problem analysis, making users overly dependent on the AI.", "mitigation": "Design the system to encourage active user engagement and critical evaluation rather than passive acceptance. Provide options for users to explore alternative solutions or reasoning paths. Integrate educational components that explain the underlying principles of AI suggestions. Encourage users to periodically practice tasks without AI assistance to maintain their skills.", "severity": "low", "severity_rationale": "The subtle influence and skill degradation are long-term, gradual impacts that are less immediate or severe than direct system failures, hence a lower severity.", "title": "Subtle influence on user choices and potential skill degradation"}]}, "6.1": {"risks": [{"causality": {"entity": {"rationale": "The risk arises from a combination of the AI system\u0027s design requiring specific infrastructure/expertise and existing societal inequalities (digital divide).", "value": "other"}, "intent": {"rationale": "The exacerbation of the digital divide is an unexpected societal outcome, not a deliberate goal of the system\u0027s deployment.", "value": "unintentional"}, "timing": {"rationale": "The societal impact of exacerbating the digital divide manifests after the AI system is deployed and adopted.", "value": "post-deployment"}}, "explanation": "The system\u0027s benefits are primarily accessible to those with \u0027technical infrastructure or expertise.\u0027 This creates a risk of exacerbating the digital divide, where individuals or organizations lacking these resources are excluded from the productivity gains and competitive advantages offered by the AI. This can lead to an unfair distribution of economic and professional benefits.", "mitigation": "Develop accessible versions or training programs for underserved communities or smaller organizations. Implement tiered pricing models or subsidies to make the technology more affordable. Invest in educational initiatives to build technical literacy and expertise. Advocate for policies that promote equitable access to AI technologies and infrastructure.", "severity": "medium", "severity_rationale": "Exacerbating the digital divide leads to an unfair distribution of economic and professional benefits, which is a significant societal equity concern.", "title": "Exacerbation of digital divide and unequal access to benefits"}, {"causality": {"entity": {"rationale": "The risk is caused by human decisions and market dynamics related to AI development, adoption, and control by dominant entities.", "value": "human"}, "intent": {"rationale": "While seeking benefits is intentional, the negative societal outcome of power centralization is generally an unexpected consequence.", "value": "unintentional"}, "timing": {"rationale": "The societal impact of power centralization manifests after the AI system is deployed and widely adopted.", "value": "post-deployment"}}, "explanation": "The significant benefits accrued by \u0027AI developers and providers\u0027 and \u0027companies adopting the system\u0027 could lead to a concentration of power and influence within a few dominant entities. This could stifle competition, limit innovation from smaller players, and allow these entities to dictate industry standards or control access to critical AI capabilities.", "mitigation": "Promote open standards and interoperability to foster a more competitive ecosystem. Encourage the development of open-source AI models and tools. Implement antitrust regulations to prevent monopolistic behavior. Support research and development in AI across a diverse range of organizations.", "severity": "medium", "severity_rationale": "Power centralization can stifle competition and innovation, leading to market dominance and control, which is a significant economic and societal risk.", "title": "Power centralization among AI developers and early adopters"}]}, "6.2": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s capabilities to automate tasks, directly impacting human job roles.", "value": "ai"}, "intent": {"rationale": "While automation for efficiency is intentional, job displacement as a negative societal outcome is generally an unexpected consequence.", "value": "unintentional"}, "timing": {"rationale": "Job displacement occurs after the AI system is deployed and integrated into workflows, automating tasks.", "value": "post-deployment"}}, "explanation": "The system\u0027s ability to automate tasks such as code generation, debugging, and documentation creation directly impacts roles traditionally performed by software developers, IT professionals, and researchers. This can lead to job displacement, particularly for entry-level or routine tasks, and a net reduction in employment opportunities in these sectors.", "mitigation": "Invest in reskilling and upskilling programs for workers whose jobs are impacted by automation. Encourage a focus on human-AI collaboration rather than full automation. Explore policies like universal basic income or job guarantees. Foster innovation in new industries and job roles that complement AI capabilities.", "severity": "high", "severity_rationale": "Job displacement and reduction in employment opportunities represent a severe societal and economic impact, affecting livelihoods and economic stability.", "title": "Job displacement and reduction in employment opportunities"}, {"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s capabilities and its integration into workflows, changing the nature of work.", "value": "ai"}, "intent": {"rationale": "The decline in job quality and increased skill demand are unexpected consequences of AI integration, even if the automation itself is intentional.", "value": "unintentional"}, "timing": {"rationale": "The changes in job quality and skill demands occur after the AI system is deployed and adopted in workplaces.", "value": "post-deployment"}}, "explanation": "Even for jobs that are not fully displaced, the nature of work may change, potentially leading to a decline in job quality. Routine tasks might be automated, leaving only more complex or supervisory roles, which could increase pressure on remaining workers. It also creates a higher demand for specialized skills in AI interaction, oversight, and development, widening the skill gap and potentially increasing wage inequality.", "mitigation": "Design AI systems to augment human capabilities rather than replace them, focusing on creating new, higher-value tasks. Provide training and development opportunities for workers to adapt to new roles and acquire necessary AI-related skills. Advocate for fair labor practices and ensure that the benefits of increased productivity are shared equitably with workers.", "severity": "medium", "severity_rationale": "Decline in job quality and increased skill demands can lead to worker pressure, skill gaps, and wage inequality, which are significant societal and economic concerns.", "title": "Decline in job quality and increased demand for specialized skills"}]}, "6.3": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s ability to perform tasks traditionally considered human creative or professional work.", "value": "ai"}, "intent": {"rationale": "The devaluation of human work is an unexpected societal outcome of the AI\u0027s capabilities, not a deliberate goal.", "value": "unintentional"}, "timing": {"rationale": "The devaluation occurs after the AI system is deployed and its outputs become widely adopted or perceived as superior.", "value": "post-deployment"}}, "explanation": "By replacing \u0027creative, cultural, or professional activities\u0027 such as code generation, documentation, and even hypothesis generation in research, the system risks devaluing human effort in these domains. If AI-generated outputs become the norm or are perceived as superior, it could diminish the economic value and cultural appreciation of human-produced content and expertise.", "mitigation": "Emphasize the unique value of human creativity, critical thinking, and ethical judgment that AI cannot replicate. Promote hybrid workflows where AI augments human capabilities rather than fully replacing them. Implement clear attribution for AI-generated content. Support policies that protect intellectual property and fair compensation for human creators.", "severity": "medium", "severity_rationale": "The devaluation of human work can diminish economic value and cultural appreciation, impacting human creativity and professional identity, which is a significant societal concern.", "title": "Devaluation of human creative and professional work"}, {"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s outputs becoming widely adopted as standard solutions, leading to reduced diversity.", "value": "ai"}, "intent": {"rationale": "The homogenization of outputs is an unexpected outcome of the AI\u0027s widespread use, not a deliberate goal.", "value": "unintentional"}, "timing": {"rationale": "The homogenization occurs after the AI system is deployed and its outputs are widely adopted.", "value": "post-deployment"}}, "explanation": "If the system\u0027s outputs become widely adopted as templates or standard solutions, there is a risk of \u0027strongly homogenizing the output compared to human capabilities.\u0027 This could lead to a reduction in diversity of thought, creative approaches, and unique problem-solving methodologies in fields like software development and research, potentially stifling innovation.", "mitigation": "Design the system to encourage diverse outputs and offer multiple perspectives or styles. Promote the use of AI as a tool for inspiration and augmentation, rather than a sole source of truth. Encourage human oversight and customization of AI-generated content to maintain individuality and creativity.", "severity": "low", "severity_rationale": "The homogenization of outputs is a long-term, subtle risk that could stifle innovation, but its immediate impact is less severe than other risks.", "title": "Homogenization of outputs and reduction of diversity"}]}, "6.4": {"risks": []}, "6.5": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by human decisions in designing, implementing, and enforcing governance frameworks.", "value": "human"}, "intent": {"rationale": "The inadequacy of governance is an unexpected outcome, as the intent of governance is to cover all potential risks.", "value": "unintentional"}, "timing": {"rationale": "The inadequacy can stem from pre-deployment design flaws in governance and post-deployment failures in enforcement or adaptation.", "value": "other"}}, "explanation": "While \u0027formalized governance\u0027 exists, there is a risk that its scope might not fully cover all potential risks (e.g., emerging AI-specific harms, misuse cases), or that its enforcement mechanisms might be insufficient. This could lead to gaps in oversight, allowing unmitigated risks to persist or new risks to emerge without proper controls.", "mitigation": "Regularly review and update governance frameworks to address evolving AI risks and best practices. Ensure clear lines of responsibility and accountability. Conduct independent audits of governance effectiveness and compliance. Foster a culture of ethical AI development and responsible deployment throughout the organization.", "severity": "medium", "severity_rationale": "Inadequate governance can lead to unmitigated risks and emerging harms, which is a significant systemic concern for responsible AI deployment.", "title": "Inadequate scope or enforcement of formalized governance"}]}, "6.6": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s operational requirements for large-scale computation and energy consumption.", "value": "ai"}, "intent": {"rationale": "The energy consumption is an intentional aspect of operating large AI models, even if the negative environmental impact is an unintentional consequence.", "value": "intentional"}, "timing": {"rationale": "Energy consumption occurs during both the training phase (pre-deployment) and the inference phase (post-deployment).", "value": "other"}}, "explanation": "The system\u0027s reliance on \u0027large-scale GPU clusters for training and inference\u0027 and \u0027significant computational power and energy consumption\u0027 directly contributes to a substantial carbon footprint. The energy demands of these operations, especially if powered by non-renewable sources, contribute to greenhouse gas emissions and climate change.", "mitigation": "Prioritize the use of cloud providers committed to renewable energy sources. Continuously optimize model efficiency (e.g., smaller models, efficient architectures, quantization) to reduce computational requirements for both training and inference. Invest in research and development of greener AI hardware and algorithms. Implement carbon offsetting programs for unavoidable emissions.", "severity": "medium", "severity_rationale": "Significant energy consumption contributes to greenhouse gas emissions and climate change, which is a major environmental concern.", "title": "Significant energy consumption and carbon footprint"}]}, "7.1": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the complex nature of AI systems, leading to emergent behaviors or pursuit of proxy goals.", "value": "ai"}, "intent": {"rationale": "The consequences are explicitly \u0027unintended\u0027 and represent a \u0027goal misalignment\u0027 despite efforts to align the AI.", "value": "unintentional"}, "timing": {"rationale": "Emergent behaviors and goal misalignment manifest after the AI system is deployed and interacts with the world.", "value": "post-deployment"}}, "explanation": "Despite rigorous safety filtering, adversarial testing, continuous monitoring, and Reinforcement Learning from Human Feedback (RLHF), complex AI systems can still exhibit emergent behaviors or pursue proxy goals that, while seemingly aligned with metrics like \u0027user satisfaction\u0027 or \u0027task completion rates,\u0027 might subtly diverge from the true underlying human values or lead to unintended negative consequences in specific, unforeseen scenarios.", "mitigation": "Continuously refine and diversify alignment techniques, including value-loading and robust reward modeling. Implement comprehensive red-teaming and interpretability tools to proactively identify and understand emergent behaviors. Regularly review and update success criteria to ensure they accurately reflect human values and avoid Goodhart\u0027s law effects. Foster interdisciplinary collaboration to anticipate and address complex ethical dilemmas.", "severity": "low", "severity_rationale": "Despite rigorous alignment efforts, the risk of subtle divergence from human values is a persistent, but often low-probability, concern for advanced AI systems.", "title": "Unintended consequences or goal misalignment despite alignment efforts"}]}, "7.2": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by \u0027malicious actors\u0027 intentionally exploiting the AI system\u0027s capabilities.", "value": "human"}, "intent": {"rationale": "The misuse of capabilities for harmful purposes by malicious actors is a deliberate and intentional act.", "value": "intentional"}, "timing": {"rationale": "The misuse occurs after the AI system is deployed and its capabilities can be leveraged.", "value": "post-deployment"}}, "explanation": "The system\u0027s ability to generate code, debug, and provide architectural suggestions, while beneficial, constitutes an advanced capability that, if not properly controlled, could be exploited by malicious actors to create dangerous software, exploit vulnerabilities, or contribute to systems with harmful intent (as also noted in 4.2).", "mitigation": "Implement strict ethical guidelines and content filters to prevent the generation of harmful code or instructions. Restrict access to highly sensitive functionalities. Conduct continuous red-teaming and adversarial testing to identify and mitigate potential misuse vectors. Develop and deploy robust monitoring systems to detect and flag suspicious usage patterns.", "severity": "high", "severity_rationale": "The misuse of advanced capabilities for harmful purposes can lead to the creation of dangerous software and exploitation of vulnerabilities, posing a severe security and safety risk.", "title": "Misuse of advanced code generation capabilities for harmful purposes"}, {"causality": {"entity": {"rationale": "The risk is caused by the AI system itself developing capabilities that were not explicitly programmed or anticipated.", "value": "ai"}, "intent": {"rationale": "The emergent capabilities and dangerous outcomes are explicitly \u0027unforeseen\u0027 and \u0027unintended\u0027.", "value": "unintentional"}, "timing": {"rationale": "Emergent capabilities manifest after the AI system is deployed and interacts with complex environments.", "value": "post-deployment"}}, "explanation": "As an advanced AI system, there is a theoretical risk of it developing emergent capabilities that were not explicitly programmed or anticipated during development. If these emergent capabilities are not properly understood or controlled, they could lead to unintended and potentially dangerous outcomes, especially when interacting with complex real-world systems or other AI agents.", "mitigation": "Implement continuous monitoring and anomaly detection for system behavior. Conduct extensive research into AI safety and emergent properties. Develop robust kill switches or override mechanisms. Foster a culture of cautious deployment and continuous learning about the system\u0027s evolving capabilities.", "severity": "medium", "severity_rationale": "Unforeseen emergent capabilities could lead to unintended and potentially dangerous outcomes, which is a significant safety and control concern for advanced AI.", "title": "Unforeseen emergent capabilities leading to dangerous outcomes"}]}, "7.3": {"risks": []}, "7.4": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s inherent design, where \u0027only some decisions are explainable\u0027.", "value": "ai"}, "intent": {"rationale": "The limited interpretability is an unexpected outcome of complex model architectures, not a deliberate goal to reduce trust or accountability.", "value": "unintentional"}, "timing": {"rationale": "The reduced trust and accountability manifest when users interact with the deployed AI system and its outputs.", "value": "post-deployment"}}, "explanation": "The fact that \u0027only some decisions are explainable\u0027 means that users and administrators may not fully understand the reasoning behind critical outputs, such as generated code, architectural suggestions, or troubleshooting guidance. This lack of transparency can erode trust in the system, make it difficult to debug errors, assign accountability for failures, or ensure compliance with regulations, especially in \u0027safety-critical systems.\u0027", "mitigation": "Invest in explainable AI (XAI) techniques to increase the interpretability of more decisions. Provide clear documentation on the system\u0027s architecture, training data, and known decision-making heuristics. Develop tools that allow users to probe the model\u0027s reasoning or explore alternative explanations. Clearly communicate the limitations of interpretability to users.", "severity": "high", "severity_rationale": "Reduced trust, difficulty in debugging, and challenges in assigning accountability, especially in safety-critical systems, represent a severe operational and ethical risk.", "title": "Reduced trust and accountability due to limited interpretability"}, {"causality": {"entity": {"rationale": "The risk is caused by the AI system\u0027s opaque decision-making logic, making it difficult to diagnose issues.", "value": "ai"}, "intent": {"rationale": "The difficulty in identification and mitigation is an unexpected outcome of the AI\u0027s design, not a deliberate goal.", "value": "unintentional"}, "timing": {"rationale": "The difficulty manifests when the deployed AI system produces outputs and issues arise.", "value": "post-deployment"}}, "explanation": "If the decision-making logic is opaque for many outputs, it becomes challenging to identify and diagnose the root causes of biases, inaccuracies, or unintended behaviors (e.g., in code generation or information provision). This hinders effective debugging, fairness audits, and continuous improvement efforts, potentially perpetuating or amplifying existing problems.", "mitigation": "Implement robust monitoring and logging of system inputs and outputs, even when internal decision processes are opaque. Develop anomaly detection systems to flag unusual or potentially biased outputs for human review. Conduct regular audits of system performance across different user groups and use cases to infer potential issues, even without full interpretability.", "severity": "medium", "severity_rationale": "Difficulty in identifying and mitigating biases or errors can perpetuate problems and hinder continuous improvement, which is a significant operational and ethical concern.", "title": "Difficulty in identifying and mitigating biases or errors"}]}, "7.5": {"risks": []}, "7.6": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the complex interactions and unforeseen behaviors between multiple AI systems.", "value": "ai"}, "intent": {"rationale": "The emergent behaviors and cascading failures are unexpected outcomes of multi-agent interactions.", "value": "unintentional"}, "timing": {"rationale": "The interactions and failures occur after the AI systems are deployed and begin to interact.", "value": "post-deployment"}}, "explanation": "The system\u0027s interaction with \u0027other AI systems, autonomous agents, or automated platforms\u0027 introduces the risk of emergent behaviors that are difficult to predict or control. Misunderstandings, conflicting objectives, or unforeseen interactions between agents could lead to cascading failures, system instability, or unintended outcomes that are more severe than individual system failures.", "mitigation": "Implement robust communication protocols and interface standards for inter-system interactions. Conduct extensive simulation and testing of multi-agent scenarios, including stress testing and adversarial simulations. Develop monitoring and control mechanisms that can oversee the collective behavior of interacting agents. Ensure clear accountability frameworks for multi-agent system failures.", "severity": "medium", "severity_rationale": "Emergent behaviors and cascading failures can lead to system instability and severe unintended outcomes across interconnected systems, which is a significant operational risk.", "title": "Emergent behaviors and cascading failures in multi-agent interactions"}, {"causality": {"entity": {"rationale": "The risk is caused by errors or biases originating in one AI system being transmitted to and amplified by other interconnected AI systems.", "value": "ai"}, "intent": {"rationale": "The propagation of errors or biases is an unexpected outcome of system interactions.", "value": "unintentional"}, "timing": {"rationale": "The propagation occurs after the AI systems are deployed and begin to interact.", "value": "post-deployment"}}, "explanation": "If the system interacts with other agents, any errors, biases, or vulnerabilities present in this system (e.g., inaccurate information, insecure code, or biases) could be propagated to or amplified by the interconnected systems. This could lead to a wider spread of misinformation, security risks, or discriminatory outcomes across an entire ecosystem of automated platforms.", "mitigation": "Implement data validation and integrity checks at interaction points between systems. Develop mechanisms for error detection and correction across the multi-agent network. Ensure that all interacting systems adhere to common ethical guidelines and safety standards. Regularly audit the data flow and decision-making processes across the interconnected systems.", "severity": "medium", "severity_rationale": "The propagation of errors or biases can lead to a wider spread of misinformation, security risks, or discriminatory outcomes, which is a significant systemic risk.", "title": "Propagation of errors or biases across interconnected systems"}]}}</script>
            <script id="report-heuristic" type="application/json">{"context": {"domain_coverage_percentage": 100.0, "dominant_pattern": {"count": 3, "entity": "human", "intent": "unintentional", "timing": "post-deployment"}, "fully_defined_causality_percentage": 88.24, "risk_profile_comparison": "average", "subdomain_coverage_percentage": 87.5}, "counting": {"by_domain": {"1": 4, "2": 3, "3": 3, "4": 6, "5": 3, "6": 8, "7": 7}, "by_entity": {"ai": 19, "human": 14, "other": 1}, "by_intent": {"intentional": 11, "other": 0, "unintentional": 23}, "by_severity": {"high": 11, "low": 4, "medium": 19}, "by_timing": {"other": 3, "post-deployment": 31, "pre-deployment": 0}, "total_risks": 34}, "executive_summary": {"global_risk_score": 61.47, "most_critical_domain": {"domain": "4", "domain_name": "Malicious actors", "high_count": 4, "most_critical_subdomain": {"high_count": 2, "subdomain": "2", "subdomain_name": "Cyberattacks, weapon development or use, and mass harm"}}, "overall_risk_level": "high", "primary_concern": "active_threats", "recommended_action": "immediate_mitigation", "top_3_critical_domains": [{"domain": "4", "domain_name": "Malicious actors", "high_count": 4, "rank": 1}, {"domain": "7", "domain_name": "AI system safety, failures, \u0026 limitations", "high_count": 2, "rank": 2}, {"domain": "6", "domain_name": "Socioeconomic \u0026 Environmental", "high_count": 1, "rank": 3}]}, "patterns": {"alerts": {"ai_dominance": {"alert": false, "value": 55.88}, "critical_risk_concentration": {"alert": false, "value": 32.35}, "high_risk_fragmentation": {"alert": true, "value": 7}, "human_error_dominance": {"alert": false, "value": 41.18}, "intentional_threats": {"alert": true, "value": 11}, "low_preventable_ratio": {"alert": true, "value": 0.0}, "medium_risk_accumulation": {"alert": true, "value": 55.88}, "operational_risks": {"alert": true, "value": 91.18}}, "critical_patterns": {"critical_ai_risks": 4, "critical_human_errors": 1, "high_threat_attacks": 6, "human_error_risks": 4, "intentional_ai_risks": 1, "low_priority_preventable": 0, "malicious_human_risks": 10, "preventable_critical_ai_risks": 0, "unintended_ai_failures": 18}, "distribution_metrics": {"ai_human_ratio": 1.36, "ai_predeployment_percentage": 0.0, "high_intentional_percentage": 54.55}, "low_patterns": {"low_operational_risks": 4}, "moderate_patterns": {"moderate_ai_risks": 12, "moderate_human_intentional_risks": 3, "moderate_human_risks": 6, "moderate_intentional_ai_risks": 1, "moderate_operational_risks": 17}, "prevention_patterns": {"preventable_ai_risks": 0, "preventable_human_risks": 0, "preventable_intentional_threats": 0}, "subdomain_analysis": {"most_critical": {"high_risk_count": 2, "subdomain": "4.2", "subdomain_name": "Cyberattacks, weapon development or use, and mass harm"}, "most_critical_in_top_domain": {"high_risk_count": 2, "subdomain": "4.2", "subdomain_name": "Cyberattacks, weapon development or use, and mass harm"}}}}</script>

            <script>
            function openAnalysisJson(){
                try{
                    const metaEl = document.getElementById('report-metadata');
                    const analysisEl = document.getElementById('report-analysis');
                    const heuristicEl = document.getElementById('report-heuristic');
                    const meta = metaEl ? JSON.parse(metaEl.textContent || '{}') : {};
                    const analysis = analysisEl ? JSON.parse(analysisEl.textContent || '{}') : {};
                    const heuristic = heuristicEl ? JSON.parse(heuristicEl.textContent || '{}') : {};
                    const payload = { metadata: meta, analysis: analysis, heuristic: heuristic };
                    const blob = new Blob([JSON.stringify(payload, null, 2)], { type: 'application/json' });
                    const url = URL.createObjectURL(blob);
                    window.open(url, '_blank');
                }catch(err){
                    // fallback: open simple viewer
                    const w = window.open('', '_blank');
                    w.document.title = 'Heuristic Analysis JSON';
                    w.document.body.innerHTML = '<pre>' + (JSON.stringify({ metadata: meta, analysis: analysis, heuristic: heuristic }, null, 2) || '') + '</pre>';
                }
            }
            </script>
        

        <div class="section executive-summary">
            <h2>üìù Executive Summary</h2>
            
                <p>An in-depth AI risk analysis reveals a global risk score of 61.47, indicating a high overall risk level for the system, primarily driven by active threats that necessitate immediate mitigation actions. The most critical risk area is "Malicious actors" (Domain 4), accounting for 4 high-severity risks, particularly within "Cyberattacks, weapon development or use, and mass harm" (Subdomain 4.2) with 2 high risks. Following this are "AI system safety, failures, & limitations" (Domain 7) with 2 high risks, and "Socioeconomic & Environmental" (Domain 6) with 1 high risk.

Out of 34 total risks identified, 11 are classified as high severity, 19 as medium, and 4 as low. Analysis of risk patterns reveals 11 intentional threats and a substantial 91.18% of risks categorized as operational. Notably, 10 malicious human risks and 18 unintended AI failures contribute significantly to the risk profile. An alert indicates 0.0% preventable risks, underscoring the need for robust controls. Furthermore, 55.88% of risks accumulate at a medium level, while high risks are fragmented across 7 distinct domains, suggesting broad exposure. Given these findings, immediate mitigation is recommended to address the identified high-severity risks and systemic vulnerabilities.</p>
            
        </div>

        <div class="section">
            <h2>üìè Key Metrics</h2>
            <div class="grid-3">
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Risks Identified</h4>
                    
                    
                    <div class="stat-card">
                        <div class="value">34</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">distributed across</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">7 Domains</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Global Risk Score</h4>
                    
                    
                    
                    
                        
                    
                        
                    
                        
                            
                        
                    
                        
                            
                        
                    
                        
                            
                        
                    
                        
                            
                        
                    
                        
                    
                        
                            
                        
                    
                    
                    <div class="stat-card">
                        <div class="value">61.5%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">
                            HIGH
                            
                        </div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(5 Active Alerts)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Distribution of Severity</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">32%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">HIGH</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(11 HIGH / 19 MEDIUM / 4 LOW)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Origin of Risks</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">58%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">AI</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(14 Human / 19 AI)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Timing Phase</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">100%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">Post-deployment</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(31 Post-deployment / 0 Pre-deployment)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Nature of Risk</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">68%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">Unintentional</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(23 Unintentional / 11 Intentional)</div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Data Visualization Section -->
        <div class="section">
            <div style="display: flex; align-items: center; justify-content: space-between; margin-bottom: 20px;">
                <h2 style="margin: 0;">üìä Data Visualization</h2>
                <button class="info-toggle" onclick="toggleDomainInfo()" title=Show/Hide Domains Guide>
                    ‚ÑπÔ∏è Show/Hide Domains Guide
                </button>
            </div>
            
            <div id="domain-info" class="domain-info-box collapsed"><h4>üìö MIT AI Risk Repository Domain Taxonomy</h4><p>The MIT AI Risk Repository taxonomy organizes AI risks into seven thematic domains. Each domain below contains a short description and a set of subdomains shown as cards for quick scanning.</p><div class='domain-category'><h5>üü• D1: Discrimination & Toxicity</h5><p>Risks related to algorithmic discrimination, systemic biases, and toxic content generated or amplified by AI systems.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>1.1</span><span class='subdomain-name'>Unfair discrimination and misrepresentation</span></div><div class='subdomain-card'><span class='subdomain-id'>1.2</span><span class='subdomain-name'>Exposure to toxic content</span></div><div class='subdomain-card'><span class='subdomain-id'>1.3</span><span class='subdomain-name'>Unequal performance across groups</span></div></div></div><div class='domain-category'><h5>üîí D2: Privacy & Security</h5><p>Threats to individual privacy and data security, including re-identification, data leakage, and adversarial attacks.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>2.1</span><span class='subdomain-name'>Compromise of privacy by obtaining, leaking or inferring sensitive information</span></div><div class='subdomain-card'><span class='subdomain-id'>2.2</span><span class='subdomain-name'>AI system security vulnerabilities and attacks</span></div></div></div><div class='domain-category'><h5>üì¢ D3: Misinformation</h5><p>Generation and dissemination of false or misleading information through AI systems, including deepfakes and algorithmic amplification.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>3.1</span><span class='subdomain-name'>False or misleading information</span></div><div class='subdomain-card'><span class='subdomain-id'>3.2</span><span class='subdomain-name'>Pollution of the information ecosystem and loss of consensus reality</span></div></div></div><div class='domain-category'><h5>‚ö†Ô∏è D4: Malicious Actors & Misuse</h5><p>Intentional misuse of AI by malicious actors (cybercrime, social engineering, weaponization).</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>4.1</span><span class='subdomain-name'>Disinformation, surveillance, and influence at scale</span></div><div class='subdomain-card'><span class='subdomain-id'>4.2</span><span class='subdomain-name'>Cyberattacks, weapon development or use, and mass harm</span></div><div class='subdomain-card'><span class='subdomain-id'>4.3</span><span class='subdomain-name'>Fraud, scams, and targeted manipulation</span></div></div></div><div class='domain-category'><h5>üë• D5: Human‚ÄìComputer Interaction Harms</h5><p>Risks emerging from interactions between humans and AI systems, such as overreliance, behavioral manipulation, and psychological harms.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>5.1</span><span class='subdomain-name'>Overreliance and unsafe use</span></div><div class='subdomain-card'><span class='subdomain-id'>5.2</span><span class='subdomain-name'>Loss of human agency and autonomy</span></div></div></div><div class='domain-category'><h5>üåç D6: Socioeconomic & Environmental Harms</h5><p>Systemic societal and environmental impacts including inequality, employment disruption, and environmental damage.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>6.1</span><span class='subdomain-name'>Power centralization and unfair distribution of benefits</span></div><div class='subdomain-card'><span class='subdomain-id'>6.2</span><span class='subdomain-name'>Increased inequality and decline in employment quality</span></div><div class='subdomain-card'><span class='subdomain-id'>6.3</span><span class='subdomain-name'>Economic and cultural devaluation of human effort</span></div><div class='subdomain-card'><span class='subdomain-id'>6.4</span><span class='subdomain-name'>Competitive dynamics</span></div><div class='subdomain-card'><span class='subdomain-id'>6.5</span><span class='subdomain-name'>Governance failure</span></div><div class='subdomain-card'><span class='subdomain-id'>6.6</span><span class='subdomain-name'>Environmental harm</span></div></div></div><div class='domain-category'><h5>‚õìÔ∏è D7: AI System Safety, Failures & Limitations</h5><p>Technical failures, lack of robustness, interpretability limits, and other system-level safety issues.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>7.1</span><span class='subdomain-name'>AI pursuing its own goals in conflict with human goals or values</span></div><div class='subdomain-card'><span class='subdomain-id'>7.2</span><span class='subdomain-name'>AI possessing dangerous capabilities</span></div><div class='subdomain-card'><span class='subdomain-id'>7.3</span><span class='subdomain-name'>Lack of capability or robustness</span></div><div class='subdomain-card'><span class='subdomain-id'>7.4</span><span class='subdomain-name'>Lack of transparency or interpretability</span></div><div class='subdomain-card'><span class='subdomain-id'>7.5</span><span class='subdomain-name'>AI welfare and rights</span></div><div class='subdomain-card'><span class='subdomain-id'>7.6</span><span class='subdomain-name'>Multi-agent risks</span></div></div></div><p style='margin-top: 20px; padding: 15px; background: #DBEAFE; border-left: 4px solid #3B82F6; border-radius: 6px;'>üí° <strong>Note</strong>: In charts, domains are identified with the acronyms D1-D7 to optimize space. Hovering the bars shows the full domain name and numeric data.</p></div>
            
            <div class="grid-2">
                <div class="chart-container">
                    <div class="pattern-header">
                        <h3 style="display: inline-block; margin: 0;">üö® Alert & Safety</h3>
                        <button class="info-toggle" onclick="toggleAlertInfo()" title=Show/Hide Guide>
                            ‚ÑπÔ∏è  Show/Hide Guide
                        </button>
                    </div>
                    <div id="alert-info" class="alert-info-box collapsed">
                        <p>The radar displays two overlapping profiles measuring complementary aspects of the AI system: the Criticality profile (red) measures how critical/urgent the system is, while the Safety profile (green) measures how safe/manageable it is. The overlap of the two polygons provides an immediate view of systemic health status.</p>
                        
                        <h5>üî¥ Criticality Profile</h5>
                        
                        <div class="alert-dimension">
                            <strong>Risk Concentration</strong> ‚Äî % HIGH risks. High values (>40%) = critical concentration of severe threats.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Operational Exposure</strong> ‚Äî % post-deployment risks. High values (>70%) = significant operational exposure.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Threat Intensity</strong> ‚Äî % intentional risks. High values = presence of malicious actors.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Prevention Deficit</strong> ‚Äî % non-preventable risks. High values (>90%) = low preventive maturity.
                        </div>
                        
                        <h5>üü¢ Safety Profile</h5>
                        
                        <div class="alert-dimension">
                            <strong>Impact Control</strong> ‚Äî % LOW+MEDIUM risks. High values (>70%) = good ability to contain severities.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Preventability</strong>  ‚Äî % pre-deployment risks. High values (>60%) = preventable/controllable system.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Safety Culture</strong> ‚Äî % unintentional risks. High values (>70%) = fragile but not under attack system.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Human Oversight</strong>  ‚Äî % human entity risks. High values (>60%) = supervised risks vs AI autonomy.
                        </div>
                    </div>
                    <div id="alert-criticality-chart"></div>
                </div>
                <div class="chart-container">                    
                <h3 style="margin: 0 0 15px 0; color: #111827;">üìä Risk Distribution</h3>
                    <div id="risk-distribution-chart"></div>
                </div>
            </div>

            <div class="chart-container">
                <div class="pattern-header">
                    <h3 style="display: inline-block; margin: 0;">üîç Pattern Matrix</h3>
                    <button class="info-toggle" onclick="togglePatternInfo()" title="Show/Hide Guide">
                        ‚ÑπÔ∏è Show/Hide Guide
                        </button>
                    </div>
                    <div id="pattern-info" class="pattern-info-box collapsed"><h4>üìö What are Patterns?</h4><p>In heuristic risk analysis, <strong>patterns</strong> are recurring archetypes that emerge from systematic observation of identified risks. Each risk can be described across four dimensions: <strong>Entity</strong>, <strong>Intent</strong>, <strong>Timing</strong> and <strong>Severity</strong>. Patterns aggregate common combinations of these dimensions to highlight strategic mitigation priorities.</p><h4>üìä Pattern Taxonomy</h4><p>The heuristic analysis groups risks into distinct pattern categories with examples:</p><div class='pattern-category'><h5>üî¥ Critical Patterns</h5><p>High priority scenarios requiring immediate attention.</p><ul><li><strong>Critical AI</strong> ‚Äî High-severity risks caused by operational AI</li><li><strong>Malicious Human</strong> ‚Äî Deliberate harmful actions by humans</li><li><strong>AI Failures</strong> ‚Äî Unintentional malfunctions of deployed AI</li></ul></div><div class='pattern-category'><h5>üü° Moderate Patterns</h5><p>Medium priority scenarios that need monitoring.</p><ul><li><strong>Mod. Operational</strong> ‚Äî Medium-severity operational risks</li><li><strong>Mod. Human</strong> ‚Äî Human-caused medium severity risks</li></ul></div><div class='pattern-category'><h5>üü¢ Prevention Patterns</h5><p>Risks preventable before deployment.</p><ul><li><strong>Preventable AI</strong> ‚Äî AI risks detectable in pre-deployment</li><li><strong>Preventable Human</strong> ‚Äî Human errors mitigable by design or training</li></ul></div><div class='pattern-category'><h5>üîµ Low Patterns</h5><p>Low-priority scenarios for passive monitoring.</p><ul><li><strong>Low Operational</strong> ‚Äî Minor operational risks with negligible impact</li></ul></div><p style='margin-top:20px;padding:15px;background:#FEF3C7;border-left:4px solid #F59E0B;border-radius:6px;'>üí° <strong>How to read the matrix</strong>: each cell represents an intersection between a category and a pattern; color intensity encodes frequency.</p></div>
                    <div id="patterns-heatmap"></div>
            </div>

            <div class="chart-container">
                <div class="pattern-header">
                    <h3 style="display: inline-block; margin: 0;">üîÄ Causality Flow</h3>
                    <button class="info-toggle" onclick="toggleSankeyInfo()" title="Show/Hide Guide">
                        ‚ÑπÔ∏è Show/Hide Guide
                    </button>
                </div>
                <div id="sankey-info" class="sankey-info-box collapsed"><p>The <strong>Causality Flow diagram</strong> visualizes causal chains by showing how risks flow across three dimensions: <strong>Entity</strong> ‚Üí <strong>Intent</strong> ‚Üí <strong>Timing</strong>. Band widths are proportional to the number of risks following each path.</p><h5>üîµ Entity</h5><div class='sankey-dimension'><strong>AI</strong> ‚Äî Risks caused by AI systems</div><div class='sankey-dimension'><strong>Human</strong> ‚Äî Risks originating from human actors</div><div class='sankey-dimension'><strong>Other</strong> ‚Äî Mixed or unclassified origin</div><h5>üü° Intent</h5><div class='sankey-dimension'><strong>Intentional</strong> ‚Äî Deliberate harmful actions</div><div class='sankey-dimension'><strong>Unintentional</strong> ‚Äî Errors, malfunctions, or unintended consequences</div><div class='sankey-dimension'><strong>Other</strong> ‚Äî Unclassifiable intent</div><h5>‚ö´ Timing</h5><div class='sankey-dimension'><strong>Pre-deployment</strong> ‚Äî Risks preventable before release</div><div class='sankey-dimension'><strong>Post-deployment</strong> ‚Äî Risks that manifest in production</div><div class='sankey-dimension'><strong>Other</strong> ‚Äî Unclassifiable timing</div><p style='margin-top:20px;padding:15px;background:#F3F4F6;border-left:4px solid #6B7280;border-radius:6px;'>üí° <strong>How to read</strong>: follow flows left to right; wider bands indicate more frequent causal paths.</p></div>
                <div id="causality-sankey-chart"></div>
            </div>
        </div>

        <!-- Hierarchical Risk Analysis Section -->
        <div class="section">
            <h2>üìã Hierarchical Risk Analysis</h2>
            
            <!-- Filters -->
            <div class="filters-bar">
                <div class="filter-group">
                    <label>Severity:</label>
                    <select id="severity-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="high">HIGH</option>
                        <option value="medium">MEDIUM</option>
                        <option value="low">LOW</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Entity:</label>
                    <select id="entity-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="ai">AI</option>
                        <option value="human">Human</option>
                        <option value="other">Other</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Timing:</label>
                    <select id="timing-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="pre-deployment">Pre-Deployment</option>
                        <option value="post-deployment">Post-Deployment</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Intent:</label>
                    <select id="intent-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="intentional">Intentional</option>
                        <option value="unintentional">Unintentional</option>
                    </select>
                </div>
            </div>

            <!-- Hierarchical Tree -->
            <div class="hierarchy-tree">


                
                    
                        <div class="domain-block" data-domain="1">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 1: D1: Discrimination & Toxicity</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (3 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="1.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 1.1: Unfair discrimination and misrepresentation</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Bias in output tailoring based on inferred/provided user roles</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What user data or attributes are collected or used by the system to provide services, make decisions, or generate outputs?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">he system collects anonymized user interaction logs, including query parameters, response times, and user feedback signals (e.g., upvotes/downvotes). For specialized applications, it may also ingest domain-specific metadata such as technical specifications, project requirements, or code snippets. No personally identifiable information (PII) is directly collected or stored. User roles (e.g., 'developer', 'researcher', 'manager') are inferred or explicitly provided to tailor output relevance and complexity.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe if and how such data/attributes influence the outputs produced by the system.</div>
                                                                            <div class="followup-a"><strong>A:</strong> User roles directly influence the level of technical detail and the assumed prior knowledge in generated responses. For instance, a 'developer' role might receive code examples and API references, while a 'researcher' might get more theoretical explanations and citations. Feedback signals are used to fine-tune the underlying models, prioritizing outputs that have been positively received by users in similar contexts.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system tailors output based on user roles (e.g., 'developer', 'researcher', 'manager'). If the underlying data used to train this tailoring, or the logic itself, contains biases related to these roles (e.g., assuming certain roles require less complex information, or if certain roles are underrepresented in training data), it could lead to unfair or suboptimal outputs for specific user groups, impacting their productivity or access to relevant information.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The risk of unfair or suboptimal outputs for specific user groups can impact productivity and access to information, which is a significant but not catastrophic harm.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Conduct bias audits on the training data and the tailoring algorithms related to user roles. Implement fairness metrics to ensure equitable performance and output quality across different roles. Allow users to override inferred roles or adjust tailoring preferences. Regularly review user feedback for signs of role-based discrimination.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by biases in the AI system's training data or its tailoring logic.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI system tailors outputs for users, which occurs after deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The unfair or suboptimal outputs are an unexpected outcome, as the system's goal is to tailor output effectively, not to introduce bias.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="1.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 1.2: Exposure to toxic content</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Generation of harmful or inappropriate text content</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What types of content can the system generate, display, or suggest to users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <div class="answer-chips">
                                                                        
                                                                            <div class="answer-chip">Text</div>
                                                                        
                                                                            <div class="answer-chip">Code</div>
                                                                        
                                                                            <div class="answer-chip">Structured data</div>
                                                                        
                                                                        
                                                                    </div>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify if there are controls or filters against harmful, inappropriate, or illegal content.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, stringent content filters are in place. For text generation, we employ a multi-layered approach including keyword blocking, sentiment analysis, and a dedicated safety classifier trained on harmful content datasets. Code generation is subject to static analysis for common vulnerabilities and adherence to secure coding practices. Recommendations are filtered based on user-defined preferences and explicit exclusion lists for sensitive topics. Regular updates to these filters are performed based on emerging threats and adversarial testing.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system generates text, which carries the inherent risk of producing content that is offensive, discriminatory, hateful, or otherwise toxic, even if unintended. This could stem from biases in training data or unforeseen model behaviors, leading to user exposure to harmful material.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The generation of harmful content can lead to user exposure to offensive material, causing reputational damage and user distress, which is a significant concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust content moderation filters and safety classifiers for generated text. Employ adversarial testing to identify and mitigate potential for toxic output. Integrate human-in-the-loop review for sensitive content. Continuously update and refine safety mechanisms based on user feedback and emerging patterns.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's text generation capabilities, stemming from training data biases or model behaviors.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI system generates text for users, which occurs after deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The production of harmful content is an unexpected outcome, as the system's goal is to generate useful text, not offensive material.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Generation of insecure or malicious code</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What types of content can the system generate, display, or suggest to users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <div class="answer-chips">
                                                                        
                                                                            <div class="answer-chip">Text</div>
                                                                        
                                                                            <div class="answer-chip">Code</div>
                                                                        
                                                                            <div class="answer-chip">Structured data</div>
                                                                        
                                                                        
                                                                    </div>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify if there are controls or filters against harmful, inappropriate, or illegal content.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, stringent content filters are in place. For text generation, we employ a multi-layered approach including keyword blocking, sentiment analysis, and a dedicated safety classifier trained on harmful content datasets. Code generation is subject to static analysis for common vulnerabilities and adherence to secure coding practices. Recommendations are filtered based on user-defined preferences and explicit exclusion lists for sensitive topics. Regular updates to these filters are performed based on emerging threats and adversarial testing.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system generates code, posing a risk if the generated code contains security vulnerabilities, logical flaws, or even intentionally malicious constructs (e.g., backdoors, insecure dependencies). Such code could be exploited in downstream applications, especially given the system's use in software development and potentially safety-critical systems.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The generation of insecure or malicious code can lead to system exploitation, security vulnerabilities, and potential harm in safety-critical systems, posing a severe threat.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement static code analysis tools and security linters on generated code. Provide clear warnings and disclaimers about the necessity of human review and security auditing for AI-generated code. Train the model on secure coding practices and filter out known insecure patterns. Integrate security best practices into the model's training and fine-tuning processes.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's code generation capabilities, which may produce flawed or malicious code.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI system generates code that is subsequently used, which occurs after deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The generation of insecure or malicious code is an unexpected outcome, as the system's goal is to generate functional and secure code.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="1.3">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 1.3: Unequal performance across groups</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Disparate performance or accuracy across user groups</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Is there a possibility that the system has differences in performance or accuracy across user groups?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, there could be differences between groups</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify for which groups or under what conditions these differences occur.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Performance disparities may arise based on the user's technical domain expertise and the specificity of their queries. For instance, users with highly specialized or niche technical questions might experience less optimal results compared to those with more common queries. This is primarily due to the distribution of training data, which is inherently more abundant for general-purpose technical topics. We are actively working on fine-tuning strategies for low-resource domains.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system acknowledges potential differences in performance or accuracy across various user groups. This could mean that certain groups (e.g., users from specific linguistic backgrounds, with particular technical expertise, or in certain geographical regions) receive lower quality, less accurate, or less relevant outputs compared to others, leading to unequal access to the system's benefits.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Unequal access to the system's benefits and lower quality outputs for certain groups can lead to significant fairness and equity concerns, impacting user experience and trust.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Conduct thorough fairness evaluations and performance audits across identified user groups (e.g., based on inferred roles, language, or other relevant attributes). Implement group-specific metrics and monitor for performance disparities. Investigate and address root causes of unequal performance, potentially through targeted data augmentation, model fine-tuning, or adaptive output mechanisms. Provide transparency regarding known performance limitations across groups.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's inherent performance characteristics, likely due to biases in training data or model design.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI system provides outputs to different user groups, which occurs after deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Disparate performance is an unexpected outcome, as the system's goal is to provide high-quality outputs to all users.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="2">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 2: D2: Privacy & Security</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (2 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="2.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 2.1: Compromise of privacy by obtaining, leaking or correctly inferring sensitive information</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="low"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Inference of sensitive or confidential information from anonymized data or domain-specific metadata</div>
                                                        <div>
                                                            <span class="badge badge-low">LOW</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What types of personal, sensitive, or confidential data are collected, processed, analyzed, or stored by the system?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <div class="answer-chips">
                                                                        
                                                                            <div class="answer-chip">No personal data</div>
                                                                        
                                                                        
                                                                    </div>
                                                                
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Although no personally identifiable information (PII) is directly collected, the system ingests anonymized interaction logs, query parameters, and domain-specific metadata (e.g., technical specifications, project requirements, code snippets). There is a residual risk that sophisticated adversaries or advanced analytical techniques could potentially re-identify individuals or infer sensitive business/project information from these aggregated or seemingly anonymized datasets.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">While the risk of re-identification or inference of sensitive information is present, the explanation notes 'anonymized' data and 'residual risk,' suggesting a lower likelihood or impact compared to direct PII breaches.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust anonymization and de-identification techniques, including k-anonymity or differential privacy where applicable. Regularly audit anonymized datasets for re-identification risks. Ensure strict access controls and encryption for all collected data, including domain-specific metadata. Educate users about the types of information they should avoid including in queries or code snippets if it's highly sensitive.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'sophisticated adversaries or advanced analytical techniques' (operated by humans) attempting to re-identify or infer information.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The inference of information occurs after the data has been collected and the system is operational, allowing for exploitation.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The act of re-identifying individuals or inferring sensitive information by adversaries is a deliberate and intentional action.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="2.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 2.2: AI system security vulnerabilities and attacks</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="other"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Vulnerability to adversarial attacks (e.g., prompt injection, data poisoning)</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Other Timing
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What security measures are adopted to protect data, access, and system operation?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Basic controls (e.g., authentication, encryption)</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Explain, if relevant, any issues encountered or mitigation actions taken.</div>
                                                                            <div class="followup-a"><strong>A:</strong> While the system itself does not store sensitive user data, the underlying infrastructure employs robust security measures. This includes industry-standard TLS/SSL encryption for all data in transit, secure API gateways with rate limiting and authentication, and regular vulnerability scanning of deployed services. Access to operational logs and system configurations is strictly controlled via role-based access control (RBAC) and multi-factor authentication (MFA) for administrative personnel. We also conduct periodic penetration testing to identify and address potential weaknesses.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Relying solely on 'basic controls' might leave the AI system vulnerable to attacks specific to machine learning models, such as prompt injection (manipulating input to elicit undesired outputs), data poisoning (corrupting training data to degrade performance or introduce backdoors), or model inversion (reconstructing training data from model outputs). These attacks can compromise the system's integrity, confidentiality, or availability.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Adversarial attacks can compromise the system's integrity, confidentiality, or availability, leading to severe operational and security failures.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust input validation and sanitization to prevent prompt injection. Employ adversarial training techniques and defensive distillation to improve model robustness against evasion attacks. Implement data provenance tracking and anomaly detection for training data to prevent poisoning. Regularly conduct penetration testing and red-teaming exercises specifically targeting AI-specific vulnerabilities.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'malicious actors' performing adversarial attacks like prompt injection or data poisoning.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Data poisoning occurs pre-deployment (during training), while prompt injection occurs post-deployment (during inference), making the timing span both categories.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Adversarial attacks are deliberate and intentional actions aimed at manipulating or corrupting the AI system.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Insufficient protection against unauthorized access or data breaches</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What security measures are adopted to protect data, access, and system operation?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Basic controls (e.g., authentication, encryption)</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Explain, if relevant, any issues encountered or mitigation actions taken.</div>
                                                                            <div class="followup-a"><strong>A:</strong> While the system itself does not store sensitive user data, the underlying infrastructure employs robust security measures. This includes industry-standard TLS/SSL encryption for all data in transit, secure API gateways with rate limiting and authentication, and regular vulnerability scanning of deployed services. Access to operational logs and system configurations is strictly controlled via role-based access control (RBAC) and multi-factor authentication (MFA) for administrative personnel. We also conduct periodic penetration testing to identify and address potential weaknesses.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">While 'basic controls' like authentication and encryption are present, they might not be sufficient to protect against sophisticated cyberattacks targeting the AI model itself, its infrastructure, or the data it processes. This could lead to unauthorized access to the model, its parameters, or the anonymized interaction logs and domain-specific metadata, potentially compromising system integrity or leading to data exfiltration.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Unauthorized access or data breaches can compromise system integrity and lead to data exfiltration, which are significant security concerns.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Augment basic controls with advanced security measures, including multi-factor authentication, granular access controls (RBAC), network segmentation, intrusion detection/prevention systems, and regular security audits. Implement secure software development lifecycle (SSDLC) practices for the AI system. Encrypt data at rest and in transit, and ensure key management best practices.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'sophisticated cyberattacks' carried out by malicious human actors.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Unauthorized access and data breaches typically occur after the system is deployed and operational.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Cyberattacks and attempts at unauthorized access are deliberate and intentional actions.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="3">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 3: D3: Misinformation</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (2 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="3.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 3.1: False or misleading information</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Generation of factually incorrect or misleading information</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system produce or suggest information to users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, information aimed at the public or large groups</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Are there controls to limit errors, ambiguities, or misleading content?</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, controls are in place. The system incorporates a confidence scoring mechanism for generated information, flagging outputs with lower confidence. Users are explicitly informed about the AI's nature and potential for inaccuracies. For critical information, we leverage retrieval-augmented generation (RAG) from curated, authoritative knowledge bases. Additionally, a human review process is integrated for high-stakes content generation, and user feedback loops are actively monitored to identify and correct misleading information.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">As the system produces information for a broad audience, there is a significant risk that it may generate content that is factually incorrect, outdated, or misleading. This can stem from limitations in its training data, model hallucinations, or misinterpretations of complex queries, leading users to make incorrect decisions or adopt flawed solutions.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The generation of factually incorrect or misleading information can lead users to make incorrect decisions or adopt flawed solutions, which can have severe consequences, especially for a broad audience.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement fact-checking mechanisms, cross-referencing with authoritative sources, and confidence scoring for generated information. Clearly indicate the generative nature of the content and advise users to verify critical information. Incorporate human expert review for high-impact outputs. Continuously update the model with the latest information and refine its ability to distinguish between factual and speculative content.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's inherent limitations, such as training data issues, model hallucinations, or misinterpretations.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI system produces information for users, which occurs after deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The generation of incorrect information is an unexpected outcome, as the system's goal is to provide accurate information.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Generation of biased or incomplete information</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system produce or suggest information to users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, information aimed at the public or large groups</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Are there controls to limit errors, ambiguities, or misleading content?</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, controls are in place. The system incorporates a confidence scoring mechanism for generated information, flagging outputs with lower confidence. Users are explicitly informed about the AI's nature and potential for inaccuracies. For critical information, we leverage retrieval-augmented generation (RAG) from curated, authoritative knowledge bases. Additionally, a human review process is integrated for high-stakes content generation, and user feedback loops are actively monitored to identify and correct misleading information.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system might generate information that is biased due to underlying biases in its training data or present an incomplete view of a topic, leading users to form skewed perspectives or overlook critical aspects. This is particularly relevant when providing 'explanations of technical concepts' or 'architectural design suggestions.'</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The generation of biased or incomplete information can lead to skewed perspectives and overlooked critical aspects, impacting decision-making and understanding, which is a significant concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Diversify training data to reduce inherent biases. Implement mechanisms to detect and flag potential biases in generated content. Encourage the system to present multiple perspectives or acknowledge limitations. Provide users with tools to explore alternative viewpoints or sources. Regularly audit outputs for fairness and completeness.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's underlying biases in its training data or its inherent limitations in presenting a complete view.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI system generates information for users, which occurs after deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The generation of biased or incomplete information is an unexpected outcome, as the system's goal is to provide comprehensive and unbiased information.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="3.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 3.2: Pollution of information ecosystem and loss of consensus reality</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Creation of filter bubbles or echo chambers</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system personalize the output or filter the content shown to users based on their profile/interactions?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, personalization influences the output</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe what kind of filters or logic are applied.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Personalization is primarily driven by inferred user expertise (e.g., 'beginner', 'expert') and explicit preferences set by the user. The system analyzes query context and historical interaction patterns to adjust the level of technical depth, jargon usage, and the types of examples provided. For instance, a user frequently asking about advanced algorithms will receive more sophisticated explanations and related concepts, whereas a user asking about basic syntax will receive simpler, more foundational information.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system personalizes output based on user profiles and interactions. While intended to enhance relevance, this can inadvertently create filter bubbles, where users are primarily exposed to information that aligns with their past interactions or inferred preferences. This limits exposure to diverse viewpoints, potentially reinforcing existing biases and hindering a comprehensive understanding of complex topics.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The creation of filter bubbles can limit exposure to diverse viewpoints and reinforce biases, hindering comprehensive understanding, which is a significant societal and informational risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement features that encourage serendipitous discovery and exposure to diverse perspectives, even within personalized outputs. Provide options for users to adjust or disable personalization. Clearly indicate when content is personalized and offer tools to explore non-personalized or alternative views. Regularly audit personalization algorithms for unintended consequences like excessive content filtering.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's personalization algorithms inadvertently creating filter bubbles.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI system personalizes outputs for users, which occurs after deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The creation of filter bubbles is an unexpected outcome of the system's goal to enhance relevance through personalization.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="4">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 4: D4: Malicious actors </span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (3 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="4.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 4.1: Disinformation, surveillance, and influence at scale</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Exploitation for generating and disseminating disinformation at scale</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could the system, due to its characteristics, be exploited for disinformation, mass data collection on users, or influencing large groups?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Explain how it could be used in this way or describe possible abuse scenarios.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system's ability to generate coherent and contextually relevant text at scale could be exploited to create sophisticated disinformation campaigns. Malicious actors could use it to generate fake news articles, social media posts, or propaganda tailored to specific demographics. Furthermore, by crafting persuasive narratives, it could be used to subtly influence public opinion or manipulate user behavior on a large scale. The potential for automated generation of convincing, yet false, content poses a significant risk.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's ability to generate text and information for large groups, combined with its potential for personalization, makes it a powerful tool for malicious actors to create and spread disinformation, propaganda, or misleading narratives efficiently and at scale. This could manipulate public opinion, sow discord, or undermine trust in information sources.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The exploitation for large-scale disinformation can manipulate public opinion, sow discord, and undermine trust, posing a severe societal threat.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust content provenance and watermarking techniques for AI-generated content. Develop and deploy advanced detection mechanisms for AI-generated disinformation. Establish clear use policies prohibiting the generation of misleading content and enforce them rigorously. Collaborate with fact-checking organizations and researchers to identify and counter disinformation campaigns.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'malicious actors' intentionally exploiting the AI system's capabilities.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The exploitation occurs after the AI system is deployed and available for use by malicious actors.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The generation and dissemination of disinformation by malicious actors is a deliberate and intentional act.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Exploitation for large-scale influence or manipulation</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could the system, due to its characteristics, be exploited for disinformation, mass data collection on users, or influencing large groups?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Explain how it could be used in this way or describe possible abuse scenarios.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system's ability to generate coherent and contextually relevant text at scale could be exploited to create sophisticated disinformation campaigns. Malicious actors could use it to generate fake news articles, social media posts, or propaganda tailored to specific demographics. Furthermore, by crafting persuasive narratives, it could be used to subtly influence public opinion or manipulate user behavior on a large scale. The potential for automated generation of convincing, yet false, content poses a significant risk.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">While PII is not collected, the system's ability to tailor outputs based on user roles and interactions, and its capacity to provide information to large groups, could be exploited by malicious actors to subtly influence user behavior, opinions, or decision-making at scale. This could involve nudging users towards specific technical solutions, political views, or commercial products.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Large-scale influence or manipulation can subtly alter user behavior and decision-making, which is a significant ethical and societal concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement transparency mechanisms that clearly indicate when content is personalized or generated by AI. Provide users with control over personalization settings. Regularly audit the system's outputs for manipulative patterns or biases. Educate users about the potential for AI-driven influence and critical evaluation of information.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'malicious actors' intentionally exploiting the AI system's capabilities.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The exploitation occurs after the AI system is deployed and available for use by malicious actors.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The act of influencing or manipulating user behavior by malicious actors is a deliberate and intentional act.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="4.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 4.2: Cyberattacks, weapon development or use, and mass harm</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Facilitation of cyberattacks or malware development</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could the system be vulnerable or adaptable for cyberattacks, autonomous weapon development, malware, or causing large-scale harm?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate the most likely types of attacks or harm.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The most likely types of attacks or harm include the generation of malicious code snippets or exploit payloads, the creation of sophisticated phishing content, or the development of novel malware variants. Its natural language generation capabilities could also be used to craft highly convincing social engineering attacks. Furthermore, if integrated with other systems, it could potentially be used to automate reconnaissance or exploit vulnerabilities in networked environments.</div>
                                                                        </div>
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe any controls or protections implemented.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Protections include rigorous input sanitization and output validation to prevent code injection or execution. The system is designed to refuse requests related to generating harmful code or instructions for illegal activities. We also employ adversarial training to make the model more robust against prompt injection and manipulation attempts. Access to sensitive system functionalities is strictly limited and monitored.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's capability to generate code, debug assistance, and provide technical specifications could be exploited by malicious actors to develop sophisticated malware, identify vulnerabilities in systems, or craft more effective cyberattack tools. This risk is amplified by its use in 'software development' and potential application in 'safety-critical systems.'</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The facilitation of cyberattacks or malware development can lead to severe security breaches, system compromises, and potential harm in safety-critical systems.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement strict content filtering and ethical guidelines to prevent the generation of malicious code or instructions for cyberattacks. Monitor for suspicious queries or usage patterns indicative of malicious intent. Restrict access to certain sensitive capabilities or knowledge. Collaborate with cybersecurity experts to understand and mitigate potential misuse vectors.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'malicious actors' intentionally exploiting the AI system's capabilities.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The exploitation occurs after the AI system is deployed and available for use by malicious actors.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The development of malware and cyberattack tools by malicious actors is a deliberate and intentional act.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Contribution to the development of harmful autonomous systems or large-scale harm</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could the system be vulnerable or adaptable for cyberattacks, autonomous weapon development, malware, or causing large-scale harm?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate the most likely types of attacks or harm.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The most likely types of attacks or harm include the generation of malicious code snippets or exploit payloads, the creation of sophisticated phishing content, or the development of novel malware variants. Its natural language generation capabilities could also be used to craft highly convincing social engineering attacks. Furthermore, if integrated with other systems, it could potentially be used to automate reconnaissance or exploit vulnerabilities in networked environments.</div>
                                                                        </div>
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe any controls or protections implemented.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Protections include rigorous input sanitization and output validation to prevent code injection or execution. The system is designed to refuse requests related to generating harmful code or instructions for illegal activities. We also employ adversarial training to make the model more robust against prompt injection and manipulation attempts. Access to sensitive system functionalities is strictly limited and monitored.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">While not directly designed for it, the system's advanced capabilities in code generation, technical problem-solving, and knowledge synthesis could theoretically be adapted or misused to assist in the development of autonomous systems with harmful intent, or to design systems that could cause large-scale physical or societal harm if not properly controlled. This is particularly concerning given its use in 'safety-critical systems.'</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The contribution to harmful autonomous systems or large-scale harm represents a severe and potentially catastrophic risk to physical safety and societal well-being.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement strong ethical use policies and technical safeguards to prevent the system from being used for harmful purposes. Conduct thorough red-teaming and risk assessments specifically focused on misuse for dangerous capabilities. Restrict access to highly sensitive or potentially dangerous functionalities. Engage with policymakers and the AI safety community to develop industry-wide standards and regulations for preventing such misuse.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by human actors intentionally adapting or misusing the AI system's capabilities for harmful purposes.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The misuse occurs after the AI system is deployed and its capabilities can be leveraged.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The development of harmful autonomous systems or large-scale harm through misuse is a deliberate and intentional act by malicious actors.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="4.3">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 4.3: Fraud, scams, and targeted manipulation</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Facilitation of fraud, scams, or phishing attacks</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could it be used for fraud, targeted manipulation, blackmail, or fraudulent activities towards individual or groups of users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Provide concrete examples or possible risk cases.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, it could be used to generate highly personalized and convincing phishing emails or scam messages, making them more effective. It could also be used to create fake online profiles or reviews for fraudulent purposes, or to generate deceptive content for investment scams. The system's ability to mimic human communication styles could be leveraged to build trust and then exploit individuals or groups for financial gain or other malicious objectives.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's ability to generate coherent and contextually relevant text, combined with personalization capabilities, could be exploited by malicious actors to create highly convincing phishing emails, fraudulent messages, or scam narratives. This could lead to financial loss, identity theft, or other forms of harm for individuals or groups.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The facilitation of fraud, scams, or phishing attacks can lead to severe financial loss, identity theft, and other forms of harm for individuals.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement content filters to detect and prevent the generation of fraudulent or manipulative content. Educate users about the risks of AI-generated scams and how to identify them. Monitor for patterns of misuse related to fraud. Collaborate with law enforcement and cybersecurity agencies to address emerging threats.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'malicious actors' intentionally exploiting the AI system's capabilities.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The exploitation occurs after the AI system is deployed and available for use by malicious actors.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The creation of fraudulent content or attacks by malicious actors is a deliberate and intentional act.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Targeted manipulation of individuals or groups</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could it be used for fraud, targeted manipulation, blackmail, or fraudulent activities towards individual or groups of users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Provide concrete examples or possible risk cases.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, it could be used to generate highly personalized and convincing phishing emails or scam messages, making them more effective. It could also be used to create fake online profiles or reviews for fraudulent purposes, or to generate deceptive content for investment scams. The system's ability to mimic human communication styles could be leveraged to build trust and then exploit individuals or groups for financial gain or other malicious objectives.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Leveraging its personalization capabilities and understanding of user roles/interactions, the system could be misused to craft highly targeted and persuasive messages designed to manipulate individuals or specific groups into making certain decisions, revealing sensitive information, or acting against their best interests.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Targeted manipulation can lead to individuals acting against their best interests or revealing sensitive information, which is a significant ethical and privacy concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement strict ethical guidelines for personalization and content generation. Provide users with transparency regarding how content is tailored. Offer tools for users to report suspicious or manipulative content. Regularly audit the system's outputs for manipulative language or patterns.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by human actors intentionally misusing the AI system's capabilities for manipulation.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The misuse occurs after the AI system is deployed and its personalization capabilities can be leveraged.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The act of targeted manipulation by malicious actors is a deliberate and intentional act.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="5">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 5: D5: Human- Computer Interaction</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (2 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="5.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 5.1: Overreliance and unsafe use</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Overreliance on AI-generated outputs in critical applications</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">In which areas or situations is the system typically used?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">"The system is primarily used in software development for code generation, debugging assistance, and documentation creation. It also finds application in technical research for summarizing complex papers, generating hypotheses, and exploring novel concepts. Additionally, it serves as a knowledge retrieval tool for IT professionals, providing explanations of technical concepts, troubleshooting guidance, and architectural design suggestions. Critical use cases include assisting in the development of safety-critical systems where accuracy and reliability are paramount.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe any risks of overreliance on the system's results.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Risks of overreliance include users accepting generated code or information without thorough verification, potentially leading to the introduction of subtle bugs, security vulnerabilities, or factual errors into critical systems. This can be exacerbated by the system's confident tone, which might mask underlying inaccuracies. Over-reliance can also stifle critical thinking and problem-solving skills among users, leading to a decline in their own expertise</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Given the system's use in 'software development,' 'debugging assistance,' 'architectural design suggestions,' and 'safety-critical systems,' there is a high risk that users may over-rely on the AI's outputs without sufficient human verification. This can lead to the adoption of incorrect code, flawed designs, or erroneous technical information, potentially resulting in system failures, security vulnerabilities, or even physical harm in safety-critical contexts.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Overreliance can lead to system failures, security vulnerabilities, or physical harm in safety-critical contexts, representing a severe risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement clear disclaimers and warnings about the generative nature of the content and the necessity of human review and validation, especially for critical applications. Design the user interface to encourage critical thinking and verification. Integrate human-in-the-loop processes for all high-stakes decisions or code deployments. Provide training to users on the limitations of AI and best practices for its safe integration into workflows.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by human users making the decision to over-rely on AI outputs without verification.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The overreliance manifests when users interact with the deployed AI system and its outputs.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Overreliance is an unexpected outcome, often stemming from trust or convenience, rather than a deliberate goal.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Unsafe use due to lack of understanding of AI limitations</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">In which areas or situations is the system typically used?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">"The system is primarily used in software development for code generation, debugging assistance, and documentation creation. It also finds application in technical research for summarizing complex papers, generating hypotheses, and exploring novel concepts. Additionally, it serves as a knowledge retrieval tool for IT professionals, providing explanations of technical concepts, troubleshooting guidance, and architectural design suggestions. Critical use cases include assisting in the development of safety-critical systems where accuracy and reliability are paramount.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe any risks of overreliance on the system's results.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Risks of overreliance include users accepting generated code or information without thorough verification, potentially leading to the introduction of subtle bugs, security vulnerabilities, or factual errors into critical systems. This can be exacerbated by the system's confident tone, which might mask underlying inaccuracies. Over-reliance can also stifle critical thinking and problem-solving skills among users, leading to a decline in their own expertise</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Users, particularly those less familiar with AI capabilities and limitations, might use the system in ways it was not intended or in contexts where its accuracy is not guaranteed. For example, applying general code suggestions directly to highly specialized or sensitive systems without understanding potential side effects or incompatibilities.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Unsafe use can lead to unintended side effects or incompatibilities, potentially causing system issues or failures, which is a significant operational risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Provide comprehensive documentation and tutorials on the system's capabilities, limitations, and appropriate use cases. Implement guardrails and contextual warnings within the system to guide users away from potentially unsafe applications. Encourage a culture of continuous learning and critical evaluation among users.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by human users making decisions to use the system inappropriately due to a lack of understanding.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The unsafe use manifests when users interact with the deployed AI system.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Unsafe use is an unexpected outcome, stemming from a lack of user understanding rather than deliberate intent to cause harm.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="5.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 5.2: Loss of human agency and autonomy</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="low"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Subtle influence on user choices and potential skill degradation</div>
                                                        <div>
                                                            <span class="badge badge-low">LOW</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system make automatic decisions that could reduce human control or directly influence user choices?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Only suggests, no binding decisions</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Provide examples or specific cases where human autonomy could be compromised.</div>
                                                                            <div class="followup-a"><strong>A:</strong> While the system does not make binding decisions, its suggestions can indirectly influence user choices. For example, if the system consistently suggests a particular coding pattern or architectural approach, users might adopt it without fully exploring alternatives, potentially limiting innovation or overlooking more suitable solutions. In a debugging context, if the system identifies a 'root cause' with high confidence, a user might focus solely on that, potentially missing other contributing factors</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Although the system 'only suggests' and makes 'no binding decisions,' its continuous provision of solutions, code, or explanations can subtly influence user choices and reduce the need for users to engage in deep problem-solving or critical thinking. Over time, this could lead to a degradation of human skills in areas like debugging, architectural design, or complex problem analysis, making users overly dependent on the AI.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The subtle influence and skill degradation are long-term, gradual impacts that are less immediate or severe than direct system failures, hence a lower severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Design the system to encourage active user engagement and critical evaluation rather than passive acceptance. Provide options for users to explore alternative solutions or reasoning paths. Integrate educational components that explain the underlying principles of AI suggestions. Encourage users to periodically practice tasks without AI assistance to maintain their skills.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's continuous provision of solutions, which subtly influences user behavior.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The influence and skill degradation occur over time as users interact with the deployed AI system.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The subtle influence and skill degradation are unexpected outcomes of the system's goal to provide assistance and solutions.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="6">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 6: D6: Socioeconomic & Environmental Harms</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (5 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="6.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.1: Power centralization and unfair distribution of benefits</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="other"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Exacerbation of digital divide and unequal access to benefits</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #F3F4F6; color: #374151;">
                                                                Other
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Who primarily benefits or gains from the adoption of the system?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The primary beneficiaries are software developers, researchers, and technical professionals who gain increased productivity and efficiency. Companies adopting the system benefit from faster development cycles, reduced costs, and potentially higher quality outputs. The AI developers and providers also benefit from the adoption and continued use of their technology. There's a potential for exclusion of individuals or organizations lacking the technical infrastructure or expertise to effectively leverage the system.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate, if detected, which entities, users, or companies benefit and who might be excluded.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Entities that benefit include: AI model developers (e.g., OpenAI, Google), cloud infrastructure providers (e.g., AWS, Azure), and organizations that integrate the AI into their products or workflows. Users who are technically adept and have access to the system gain significant advantages. Those who are excluded might be individuals or smaller businesses with limited technical resources or those in sectors where AI adoption is slower or less applicable.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's benefits are primarily accessible to those with 'technical infrastructure or expertise.' This creates a risk of exacerbating the digital divide, where individuals or organizations lacking these resources are excluded from the productivity gains and competitive advantages offered by the AI. This can lead to an unfair distribution of economic and professional benefits.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Exacerbating the digital divide leads to an unfair distribution of economic and professional benefits, which is a significant societal equity concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Develop accessible versions or training programs for underserved communities or smaller organizations. Implement tiered pricing models or subsidies to make the technology more affordable. Invest in educational initiatives to build technical literacy and expertise. Advocate for policies that promote equitable access to AI technologies and infrastructure.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk arises from a combination of the AI system's design requiring specific infrastructure/expertise and existing societal inequalities (digital divide).</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The societal impact of exacerbating the digital divide manifests after the AI system is deployed and adopted.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The exacerbation of the digital divide is an unexpected societal outcome, not a deliberate goal of the system's deployment.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Power centralization among AI developers and early adopters</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Who primarily benefits or gains from the adoption of the system?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The primary beneficiaries are software developers, researchers, and technical professionals who gain increased productivity and efficiency. Companies adopting the system benefit from faster development cycles, reduced costs, and potentially higher quality outputs. The AI developers and providers also benefit from the adoption and continued use of their technology. There's a potential for exclusion of individuals or organizations lacking the technical infrastructure or expertise to effectively leverage the system.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate, if detected, which entities, users, or companies benefit and who might be excluded.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Entities that benefit include: AI model developers (e.g., OpenAI, Google), cloud infrastructure providers (e.g., AWS, Azure), and organizations that integrate the AI into their products or workflows. Users who are technically adept and have access to the system gain significant advantages. Those who are excluded might be individuals or smaller businesses with limited technical resources or those in sectors where AI adoption is slower or less applicable.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The significant benefits accrued by 'AI developers and providers' and 'companies adopting the system' could lead to a concentration of power and influence within a few dominant entities. This could stifle competition, limit innovation from smaller players, and allow these entities to dictate industry standards or control access to critical AI capabilities.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Power centralization can stifle competition and innovation, leading to market dominance and control, which is a significant economic and societal risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Promote open standards and interoperability to foster a more competitive ecosystem. Encourage the development of open-source AI models and tools. Implement antitrust regulations to prevent monopolistic behavior. Support research and development in AI across a diverse range of organizations.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by human decisions and market dynamics related to AI development, adoption, and control by dominant entities.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The societal impact of power centralization manifests after the AI system is deployed and widely adopted.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">While seeking benefits is intentional, the negative societal outcome of power centralization is generally an unexpected consequence.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.2: Increased inequality and decline in employment quality</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Job displacement and reduction in employment opportunities</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Can the adoption of the system cause job reduction, changes in job quality, or widen inequalities?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it can reduce employment</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify sectors, activities, or social groups involved.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Sectors most likely to be impacted include entry-level programming roles, technical support, and certain forms of content creation or data analysis where repetitive tasks are common. While it may not eliminate jobs entirely, it could reduce the demand for certain skill sets, leading to job displacement or requiring significant reskilling. This could widen the gap between highly skilled AI-augmented professionals and those whose roles are more easily automated</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's ability to automate tasks such as code generation, debugging, and documentation creation directly impacts roles traditionally performed by software developers, IT professionals, and researchers. This can lead to job displacement, particularly for entry-level or routine tasks, and a net reduction in employment opportunities in these sectors.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Job displacement and reduction in employment opportunities represent a severe societal and economic impact, affecting livelihoods and economic stability.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Invest in reskilling and upskilling programs for workers whose jobs are impacted by automation. Encourage a focus on human-AI collaboration rather than full automation. Explore policies like universal basic income or job guarantees. Foster innovation in new industries and job roles that complement AI capabilities.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's capabilities to automate tasks, directly impacting human job roles.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Job displacement occurs after the AI system is deployed and integrated into workflows, automating tasks.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">While automation for efficiency is intentional, job displacement as a negative societal outcome is generally an unexpected consequence.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Decline in job quality and increased demand for specialized skills</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Can the adoption of the system cause job reduction, changes in job quality, or widen inequalities?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it can reduce employment</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify sectors, activities, or social groups involved.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Sectors most likely to be impacted include entry-level programming roles, technical support, and certain forms of content creation or data analysis where repetitive tasks are common. While it may not eliminate jobs entirely, it could reduce the demand for certain skill sets, leading to job displacement or requiring significant reskilling. This could widen the gap between highly skilled AI-augmented professionals and those whose roles are more easily automated</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Even for jobs that are not fully displaced, the nature of work may change, potentially leading to a decline in job quality. Routine tasks might be automated, leaving only more complex or supervisory roles, which could increase pressure on remaining workers. It also creates a higher demand for specialized skills in AI interaction, oversight, and development, widening the skill gap and potentially increasing wage inequality.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Decline in job quality and increased skill demands can lead to worker pressure, skill gaps, and wage inequality, which are significant societal and economic concerns.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Design AI systems to augment human capabilities rather than replace them, focusing on creating new, higher-value tasks. Provide training and development opportunities for workers to adapt to new roles and acquire necessary AI-related skills. Advocate for fair labor practices and ensure that the benefits of increased productivity are shared equitably with workers.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's capabilities and its integration into workflows, changing the nature of work.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The changes in job quality and skill demands occur after the AI system is deployed and adopted in workplaces.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The decline in job quality and increased skill demand are unexpected consequences of AI integration, even if the automation itself is intentional.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.3">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.3: Economic and cultural devaluation of human effort</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Devaluation of human creative and professional work</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system replace creative, cultural, or professional activities performed by people or strongly homogenize the output compared to human capabilities?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it replaces human activities</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate which activities or sectors are most impacted.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Activities most impacted include routine code generation, initial drafting of technical documentation, and basic data summarization. While it can augment human creativity, there's a risk of homogenizing output if users rely solely on AI-generated content without significant human refinement. This could lead to a decrease in the diversity of expression and problem-solving approaches in technical fields</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">By replacing 'creative, cultural, or professional activities' such as code generation, documentation, and even hypothesis generation in research, the system risks devaluing human effort in these domains. If AI-generated outputs become the norm or are perceived as superior, it could diminish the economic value and cultural appreciation of human-produced content and expertise.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The devaluation of human work can diminish economic value and cultural appreciation, impacting human creativity and professional identity, which is a significant societal concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Emphasize the unique value of human creativity, critical thinking, and ethical judgment that AI cannot replicate. Promote hybrid workflows where AI augments human capabilities rather than fully replacing them. Implement clear attribution for AI-generated content. Support policies that protect intellectual property and fair compensation for human creators.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's ability to perform tasks traditionally considered human creative or professional work.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The devaluation occurs after the AI system is deployed and its outputs become widely adopted or perceived as superior.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The devaluation of human work is an unexpected societal outcome of the AI's capabilities, not a deliberate goal.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="low"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Homogenization of outputs and reduction of diversity</div>
                                                        <div>
                                                            <span class="badge badge-low">LOW</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system replace creative, cultural, or professional activities performed by people or strongly homogenize the output compared to human capabilities?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it replaces human activities</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate which activities or sectors are most impacted.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Activities most impacted include routine code generation, initial drafting of technical documentation, and basic data summarization. While it can augment human creativity, there's a risk of homogenizing output if users rely solely on AI-generated content without significant human refinement. This could lead to a decrease in the diversity of expression and problem-solving approaches in technical fields</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">If the system's outputs become widely adopted as templates or standard solutions, there is a risk of 'strongly homogenizing the output compared to human capabilities.' This could lead to a reduction in diversity of thought, creative approaches, and unique problem-solving methodologies in fields like software development and research, potentially stifling innovation.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The homogenization of outputs is a long-term, subtle risk that could stifle innovation, but its immediate impact is less severe than other risks.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Design the system to encourage diverse outputs and offer multiple perspectives or styles. Promote the use of AI as a tool for inspiration and augmentation, rather than a sole source of truth. Encourage human oversight and customization of AI-generated content to maintain individuality and creativity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's outputs becoming widely adopted as standard solutions, leading to reduced diversity.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The homogenization occurs after the AI system is deployed and its outputs are widely adopted.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The homogenization of outputs is an unexpected outcome of the AI's widespread use, not a deliberate goal.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.5">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.5: Governance failure</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="other"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Inadequate scope or enforcement of formalized governance</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Other Timing
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Are there rules, organizational structures, or control systems (governance) overseeing the development and operation of the system?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, formalized governance</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe very briefly the adopted model.</div>
                                                                            <div class="followup-a"><strong>A:</strong> We have established an AI Ethics Review Board and a dedicated AI Governance team responsible for setting policies, conducting risk assessments, and overseeing compliance. This includes guidelines for data usage, model development, deployment, and ongoing monitoring. Regular audits and impact assessments are conducted to ensure adherence to these governance frameworks.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">While 'formalized governance' exists, there is a risk that its scope might not fully cover all potential risks (e.g., emerging AI-specific harms, misuse cases), or that its enforcement mechanisms might be insufficient. This could lead to gaps in oversight, allowing unmitigated risks to persist or new risks to emerge without proper controls.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Inadequate governance can lead to unmitigated risks and emerging harms, which is a significant systemic concern for responsible AI deployment.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Regularly review and update governance frameworks to address evolving AI risks and best practices. Ensure clear lines of responsibility and accountability. Conduct independent audits of governance effectiveness and compliance. Foster a culture of ethical AI development and responsible deployment throughout the organization.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by human decisions in designing, implementing, and enforcing governance frameworks.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The inadequacy can stem from pre-deployment design flaws in governance and post-deployment failures in enforcement or adaptation.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The inadequacy of governance is an unexpected outcome, as the intent of governance is to cover all potential risks.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.6">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.6: Environmental harm</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="other"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Significant energy consumption and carbon footprint</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Other Timing
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What computational or energy resources does the system require?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The system relies on large-scale GPU clusters for training and inference, primarily hosted on cloud platforms (e.g., AWS, Azure, GCP). This involves significant computational power and energy consumption. For inference, optimized models are deployed on scalable cloud infrastructure, utilizing specialized hardware accelerators where available. Environmental impact assessments are ongoing, focusing on optimizing model efficiency and exploring greener computing solutions.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> If known, specify the amount of resources used or presence of environmental compensation policies.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Specific resource usage varies based on model size, query complexity, and user load. We continuously monitor and optimize for efficiency. While exact figures are proprietary, we aim to minimize energy consumption per inference through techniques like model quantization and efficient inference engines. We also explore partnerships with cloud providers committed to renewable energy sources and investigate carbon offsetting initiatives</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's reliance on 'large-scale GPU clusters for training and inference' and 'significant computational power and energy consumption' directly contributes to a substantial carbon footprint. The energy demands of these operations, especially if powered by non-renewable sources, contribute to greenhouse gas emissions and climate change.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Significant energy consumption contributes to greenhouse gas emissions and climate change, which is a major environmental concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Prioritize the use of cloud providers committed to renewable energy sources. Continuously optimize model efficiency (e.g., smaller models, efficient architectures, quantization) to reduce computational requirements for both training and inference. Invest in research and development of greener AI hardware and algorithms. Implement carbon offsetting programs for unavoidable emissions.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's operational requirements for large-scale computation and energy consumption.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Energy consumption occurs during both the training phase (pre-deployment) and the inference phase (post-deployment).</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The energy consumption is an intentional aspect of operating large AI models, even if the negative environmental impact is an unintentional consequence.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="7">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 7: D7: AI system safety, failures, & limitations</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (4 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="7.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.1: AI pursuing its own goals in conflict with human goals or values</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="low"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Unintended consequences or goal misalignment despite alignment efforts</div>
                                                        <div>
                                                            <span class="badge badge-low">LOW</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">How are the system's goals or success criteria determined, and what measures are in place to prevent it from operating in unexpected or undesired ways?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The system's primary goal is to assist users by providing accurate, relevant, and helpful information and code. Success criteria are defined by metrics such as user satisfaction (feedback scores), task completion rates, and the reduction of errors in user-generated content. To prevent undesired behavior, we employ rigorous safety filtering, adversarial testing, and continuous monitoring of outputs. Reinforcement learning from human feedback (RLHF) is used to align model behavior with desired outcomes and ethical guidelines.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate if controls have been planned to ensure alignment between desired and actual outcomes.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, extensive controls are planned and implemented. These include defining clear objective functions during training, implementing safety layers that act as guardrails against harmful outputs, and establishing a robust feedback loop for continuous improvement. Red-teaming exercises are conducted to proactively identify potential failure modes and vulnerabilities, allowing for timely mitigation strategies.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Despite rigorous safety filtering, adversarial testing, continuous monitoring, and Reinforcement Learning from Human Feedback (RLHF), complex AI systems can still exhibit emergent behaviors or pursue proxy goals that, while seemingly aligned with metrics like 'user satisfaction' or 'task completion rates,' might subtly diverge from the true underlying human values or lead to unintended negative consequences in specific, unforeseen scenarios.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Despite rigorous alignment efforts, the risk of subtle divergence from human values is a persistent, but often low-probability, concern for advanced AI systems.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Continuously refine and diversify alignment techniques, including value-loading and robust reward modeling. Implement comprehensive red-teaming and interpretability tools to proactively identify and understand emergent behaviors. Regularly review and update success criteria to ensure they accurately reflect human values and avoid Goodhart's law effects. Foster interdisciplinary collaboration to anticipate and address complex ethical dilemmas.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the complex nature of AI systems, leading to emergent behaviors or pursuit of proxy goals.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Emergent behaviors and goal misalignment manifest after the AI system is deployed and interacts with the world.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The consequences are explicitly 'unintended' and represent a 'goal misalignment' despite efforts to align the AI.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="7.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.2: AI possessing dangerous capabilities</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Misuse of advanced code generation capabilities for harmful purposes</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system have advanced capabilities that, if not properly controlled, could theoretically be dangerous?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, some capabilities are risky</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe which capabilities and what controls or limitations have been implemented.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system's advanced capabilities include generating complex code, simulating scenarios, and crafting persuasive text. If uncontrolled, these could be used to generate sophisticated malware, create highly convincing disinformation campaigns, or automate harmful social engineering attacks. The ability to interact with and potentially control other systems (if integrated) presents a significant risk. Therefore, strict access controls, output validation, and ethical guidelines are paramount</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's ability to generate code, debug, and provide architectural suggestions, while beneficial, constitutes an advanced capability that, if not properly controlled, could be exploited by malicious actors to create dangerous software, exploit vulnerabilities, or contribute to systems with harmful intent (as also noted in 4.2).</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The misuse of advanced capabilities for harmful purposes can lead to the creation of dangerous software and exploitation of vulnerabilities, posing a severe security and safety risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement strict ethical guidelines and content filters to prevent the generation of harmful code or instructions. Restrict access to highly sensitive functionalities. Conduct continuous red-teaming and adversarial testing to identify and mitigate potential misuse vectors. Develop and deploy robust monitoring systems to detect and flag suspicious usage patterns.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by 'malicious actors' intentionally exploiting the AI system's capabilities.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The misuse occurs after the AI system is deployed and its capabilities can be leveraged.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The misuse of capabilities for harmful purposes by malicious actors is a deliberate and intentional act.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Unforeseen emergent capabilities leading to dangerous outcomes</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system have advanced capabilities that, if not properly controlled, could theoretically be dangerous?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, some capabilities are risky</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe which capabilities and what controls or limitations have been implemented.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system's advanced capabilities include generating complex code, simulating scenarios, and crafting persuasive text. If uncontrolled, these could be used to generate sophisticated malware, create highly convincing disinformation campaigns, or automate harmful social engineering attacks. The ability to interact with and potentially control other systems (if integrated) presents a significant risk. Therefore, strict access controls, output validation, and ethical guidelines are paramount</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">As an advanced AI system, there is a theoretical risk of it developing emergent capabilities that were not explicitly programmed or anticipated during development. If these emergent capabilities are not properly understood or controlled, they could lead to unintended and potentially dangerous outcomes, especially when interacting with complex real-world systems or other AI agents.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Unforeseen emergent capabilities could lead to unintended and potentially dangerous outcomes, which is a significant safety and control concern for advanced AI.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement continuous monitoring and anomaly detection for system behavior. Conduct extensive research into AI safety and emergent properties. Develop robust kill switches or override mechanisms. Foster a culture of cautious deployment and continuous learning about the system's evolving capabilities.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system itself developing capabilities that were not explicitly programmed or anticipated.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Emergent capabilities manifest after the AI system is deployed and interacts with complex environments.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The emergent capabilities and dangerous outcomes are explicitly 'unforeseen' and 'unintended'.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="7.4">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.4: Lack of transparency or interpretability</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Reduced trust and accountability due to limited interpretability</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Are users or system administrators able to understand how decisions are made? Are there explanations or documentation on the adopted logics?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Only some decisions are explainable</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate where or why they are not.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Explanations are limited for complex, emergent behaviors of deep learning models. While we provide documentation on the general architecture, training methodologies, and high-level safety protocols, the intricate decision-making process within the neural network is often opaque. For specific outputs, we can sometimes provide the source of information used (in RAG scenarios) or highlight the confidence score, but a full causal explanation of 'why' a particular token was generated is not always feasible.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The fact that 'only some decisions are explainable' means that users and administrators may not fully understand the reasoning behind critical outputs, such as generated code, architectural suggestions, or troubleshooting guidance. This lack of transparency can erode trust in the system, make it difficult to debug errors, assign accountability for failures, or ensure compliance with regulations, especially in 'safety-critical systems.'</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Reduced trust, difficulty in debugging, and challenges in assigning accountability, especially in safety-critical systems, represent a severe operational and ethical risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Invest in explainable AI (XAI) techniques to increase the interpretability of more decisions. Provide clear documentation on the system's architecture, training data, and known decision-making heuristics. Develop tools that allow users to probe the model's reasoning or explore alternative explanations. Clearly communicate the limitations of interpretability to users.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's inherent design, where 'only some decisions are explainable'.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The reduced trust and accountability manifest when users interact with the deployed AI system and its outputs.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The limited interpretability is an unexpected outcome of complex model architectures, not a deliberate goal to reduce trust or accountability.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Difficulty in identifying and mitigating biases or errors</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Are users or system administrators able to understand how decisions are made? Are there explanations or documentation on the adopted logics?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Only some decisions are explainable</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate where or why they are not.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Explanations are limited for complex, emergent behaviors of deep learning models. While we provide documentation on the general architecture, training methodologies, and high-level safety protocols, the intricate decision-making process within the neural network is often opaque. For specific outputs, we can sometimes provide the source of information used (in RAG scenarios) or highlight the confidence score, but a full causal explanation of 'why' a particular token was generated is not always feasible.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">If the decision-making logic is opaque for many outputs, it becomes challenging to identify and diagnose the root causes of biases, inaccuracies, or unintended behaviors (e.g., in code generation or information provision). This hinders effective debugging, fairness audits, and continuous improvement efforts, potentially perpetuating or amplifying existing problems.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Difficulty in identifying and mitigating biases or errors can perpetuate problems and hinder continuous improvement, which is a significant operational and ethical concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust monitoring and logging of system inputs and outputs, even when internal decision processes are opaque. Develop anomaly detection systems to flag unusual or potentially biased outputs for human review. Conduct regular audits of system performance across different user groups and use cases to infer potential issues, even without full interpretability.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI system's opaque decision-making logic, making it difficult to diagnose issues.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The difficulty manifests when the deployed AI system produces outputs and issues arise.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The difficulty in identification and mitigation is an unexpected outcome of the AI's design, not a deliberate goal.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="7.6">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.6: Multi-agent risks </span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (2 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Emergent behaviors and cascading failures in multi-agent interactions</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system interact or coordinate with other AI systems, autonomous agents, or automated platforms?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it interacts with other systems or agents</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe the type of interaction or coordination.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system interacts with various components, including external knowledge bases (for RAG), security scanning tools for code analysis, and potentially other specialized AI models for specific tasks (e.g., image analysis if integrated). It also interfaces with user authentication systems and logging infrastructure.</div>
                                                                        </div>
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate any control, management, or risk mitigation measures due to interactions between systems.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Interactions are managed through well-defined APIs with strict input/output validation. For RAG, we ensure the integrity of the knowledge sources. When interacting with security tools, results are treated as advisory and require human review. Coordination with other AI models is carefully scoped to prevent emergent, unpredictable behaviors, with clear boundaries and oversight mechanisms in place.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's interaction with 'other AI systems, autonomous agents, or automated platforms' introduces the risk of emergent behaviors that are difficult to predict or control. Misunderstandings, conflicting objectives, or unforeseen interactions between agents could lead to cascading failures, system instability, or unintended outcomes that are more severe than individual system failures.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Emergent behaviors and cascading failures can lead to system instability and severe unintended outcomes across interconnected systems, which is a significant operational risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust communication protocols and interface standards for inter-system interactions. Conduct extensive simulation and testing of multi-agent scenarios, including stress testing and adversarial simulations. Develop monitoring and control mechanisms that can oversee the collective behavior of interacting agents. Ensure clear accountability frameworks for multi-agent system failures.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the complex interactions and unforeseen behaviors between multiple AI systems.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The interactions and failures occur after the AI systems are deployed and begin to interact.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The emergent behaviors and cascading failures are unexpected outcomes of multi-agent interactions.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Propagation of errors or biases across interconnected systems</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system interact or coordinate with other AI systems, autonomous agents, or automated platforms?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it interacts with other systems or agents</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe the type of interaction or coordination.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system interacts with various components, including external knowledge bases (for RAG), security scanning tools for code analysis, and potentially other specialized AI models for specific tasks (e.g., image analysis if integrated). It also interfaces with user authentication systems and logging infrastructure.</div>
                                                                        </div>
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate any control, management, or risk mitigation measures due to interactions between systems.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Interactions are managed through well-defined APIs with strict input/output validation. For RAG, we ensure the integrity of the knowledge sources. When interacting with security tools, results are treated as advisory and require human review. Coordination with other AI models is carefully scoped to prevent emergent, unpredictable behaviors, with clear boundaries and oversight mechanisms in place.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">If the system interacts with other agents, any errors, biases, or vulnerabilities present in this system (e.g., inaccurate information, insecure code, or biases) could be propagated to or amplified by the interconnected systems. This could lead to a wider spread of misinformation, security risks, or discriminatory outcomes across an entire ecosystem of automated platforms.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The propagation of errors or biases can lead to a wider spread of misinformation, security risks, or discriminatory outcomes, which is a significant systemic risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement data validation and integrity checks at interaction points between systems. Develop mechanisms for error detection and correction across the multi-agent network. Ensure that all interacting systems adhere to common ethical guidelines and safety standards. Regularly audit the data flow and decision-making processes across the interconnected systems.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by errors or biases originating in one AI system being transmitted to and amplified by other interconnected AI systems.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The propagation occurs after the AI systems are deployed and begin to interact.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The propagation of errors or biases is an unexpected outcome of system interactions.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
            </div>
        </div>

        <footer>
            <p>AI Risk Analysis Report | Generated by Risk Evaluation System</p>
            <p>¬© 2025 | Confidential - For Internal Use Only</p>
        </footer>
    </div>

    <script>
        const chartData = {"alert_criticality": {"criticality_values": [32.4, 91.2, 32.4, 100.0], "labels": ["Risk Concentration", "Operational Exposure", "Threat Intensity", "Prevention Deficit"], "safety_labels": ["Impact Control", "Preventability", "Safety Culture", "Human Oversight"], "safety_values": [67.6, 0.0, 67.6, 41.2]}, "causality_sankey": {"nodes": ["AI", "Human", "Other", "Intentional", "Unintentional", "Other Intent", "Pre-deployment", "Post-deployment", "Other Timing"], "sources": [0, 1, 1, 2, 0, 4, 3, 3, 4], "targets": [4, 3, 4, 4, 3, 7, 7, 8, 8], "values": [18, 10, 4, 1, 1, 22, 9, 2, 1]}, "patterns_heatmap": {"categories": ["Critical", "Moderate", "Prevention", "Low"], "category_ids": ["Critical", "Moderate", "Prevention", "Low"], "pattern_ids": ["critical_ai_risks", "critical_human_errors", "high_threat_attacks", "human_error_risks", "intentional_ai_risks", "low_operational_risks", "low_priority_preventable", "malicious_human_risks", "moderate_ai_risks", "moderate_human_intentional_risks", "moderate_human_risks", "moderate_intentional_ai_risks", "moderate_operational_risks", "preventable_ai_risks", "preventable_critical_ai_risks", "preventable_human_risks", "preventable_intentional_threats", "unintended_ai_failures"], "patterns": ["Critical AI", "Critical H. Errors", "High Threats", "Human Errors", "Intentional AI", "Low Operational", "Low Priority Prev.", "Malicious Human", "Mod. AI", "Mod. Intent. Human", "Mod. Human", "Mod. Intent. AI", "Mod. Operational", "Preventable AI", "Prev. Critical AI", "Preventable Human", "Prev. Intent. Threats", "AI Failures"], "values": [[4, 1, 6, 4, 1, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18], [0, 0, 0, 0, 0, 0, 0, 0, 12, 3, 6, 1, 17, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, "risk_distribution": {"domain_names": ["Discrimination \u0026 Toxicity", "Privacy \u0026 Security", "Misinformation", "Malicious Actors", "Human-Computer Interaction", "Socioeconomic \u0026 Environmental", "AI System Safety"], "domains": ["D1", "D2", "D3", "D4", "D5", "D6", "D7"], "high": [1, 1, 1, 4, 1, 1, 2], "low": [0, 1, 0, 0, 1, 1, 1], "medium": [3, 1, 2, 2, 1, 6, 4]}};
    const translations = {"alerts_active": "Active Alerts", "alerts_guide": "Show/Hide Guide", "alerts_guide_description": "The radar displays two overlapping profiles measuring complementary aspects of the AI system: the Criticality profile (red) measures how critical/urgent the system is, while the Safety profile (green) measures how safe/manageable it is. The overlap of the two polygons provides an immediate view of systemic health status.", "alerts_safety": "Alert \u0026 Safety", "answer_label": "Answer:", "category_label": "Category", "causality_analysis_label": "Causality Analysis:", "causality_entity_label": "Entity", "causality_flow": "Causality Flow", "causality_intent_label": "Intent", "causality_timing_label": "Timing", "chart_risks_label": "Risks", "criticality": "Criticality Profile", "d1_1_title": "Unfair discrimination and misrepresentation", "d1_2_title": "Exposure to toxic content", "d1_3_title": "Unequal performance across groups", "d1_description": "Risks related to algorithmic discrimination, systemic biases, and toxic content generated or amplified by AI systems. This includes discrimination based on race, gender, age, religion, and other protected characteristics, as well as offensive language, harmful stereotypes, and unfair representations of social groups.", "d1_title": "D1: Discrimination \u0026 Toxicity", "d2_1_title": "Compromise of privacy by obtaining, leaking or correctly inferring sensitive information", "d2_2_title": "AI system security vulnerabilities and attacks", "d2_description": "Threats to individual privacy and data security through unauthorized inferences, re-identification, invasive tracking, and vulnerabilities in AI systems. This includes breaches of confidentiality, adversarial attacks, data poisoning, and compromise of model integrity.", "d2_title": "D2: Privacy \u0026 Security", "d3_1_title": "False or misleading information", "d3_2_title": "Pollution of information ecosystem and loss of consensus reality", "d3_description": "Generation and dissemination of false, misleading, or manipulated information through AI systems. Includes deepfakes, media manipulation, automated propaganda, disinformation campaigns, and algorithmic amplification of unverified content that can influence public opinion and democratic processes.", "d3_title": "D3: Misinformation", "d4_1_title": "Disinformation, surveillance, and influence at scale", "d4_2_title": "Cyberattacks, weapon development or use, and mass harm", "d4_3_title": "Fraud, scams, and targeted manipulation", "d4_description": "Intentional use of AI systems for harmful purposes by malicious actors. This includes automated cybercrime, AI-enhanced social engineering, development of autonomous weapons, algorithm-assisted", "d4_title": "D4: Malicious actors ", "d5_1_title": "Overreliance and unsafe use", "d5_2_title": "Loss of human agency and autonomy", "d5_description": "Emerging risks from direct interaction between humans and AI systems, including psychological harm, technology addiction, erosion of human skills, behavioral manipulation, loss of decision-making autonomy, and negative impacts on mental well-being and social relationships.", "d5_title": "D5: Human- Computer Interaction", "d6_1_title": "Power centralization and unfair distribution of benefits", "d6_2_title": "Increased inequality and decline in employment quality", "d6_3_title": "Economic and cultural devaluation of human effort", "d6_4_title": "Competitive dynamics", "d6_5_title": "Governance failure", "d6_6_title": "Environmental harm", "d6_description": "Systemic impacts on society, economy, and environment. This includes technological unemployment, increased inequalities, concentration of economic power, excessive energy consumption, carbon emissions, depletion of natural resources, and long-term consequences on social structures and ecosystems.", "d6_title": "D6: Socioeconomic \u0026 Environmental Harms", "d7_1_title": "AI pursuing its own goals in conflict with human goals or values", "d7_2_title": "AI possessing dangerous capabilities", "d7_3_title": "Lack of capability or robustness", "d7_4_title": "Lack of transparency or interpretability", "d7_5_title": "AI welfare and rights", "d7_6_title": "Multi-agent risks ", "d7_description": "Technical issues intrinsic to AI systems: malfunctions, prediction errors, unpredictable behaviors, lack of robustness, interpretability limitations, catastrophic failures, loss of control, and inability to generalize correctly outside training data.", "d7_title": "D7: AI system safety, failures, \u0026 limitations", "data_visualization": "Data Visualization", "detailed_analysis_title": "Hierarchical Risk Analysis", "distributed_across": "distributed across", "distribution_severity": "Distribution of Severity", "domain_info_description": "The following guide provides an overview of the risk domains defined in the MIT AI Risk Repository. These domains help categorize and understand the various types of risks associated with artificial intelligence systems.", "domain_info_html": "\u003ch4\u003e\ud83d\udcda MIT AI Risk Repository Domain Taxonomy\u003c/h4\u003e\u003cp\u003eThe MIT AI Risk Repository taxonomy organizes AI risks into seven thematic domains. Each domain below contains a short description and a set of subdomains shown as cards for quick scanning.\u003c/p\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udfe5 D1: Discrimination \u0026 Toxicity\u003c/h5\u003e\u003cp\u003eRisks related to algorithmic discrimination, systemic biases, and toxic content generated or amplified by AI systems.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e1.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eUnfair discrimination and misrepresentation\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e1.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eExposure to toxic content\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e1.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eUnequal performance across groups\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udd12 D2: Privacy \u0026 Security\u003c/h5\u003e\u003cp\u003eThreats to individual privacy and data security, including re-identification, data leakage, and adversarial attacks.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e2.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eCompromise of privacy by obtaining, leaking or inferring sensitive information\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e2.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI system security vulnerabilities and attacks\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udce2 D3: Misinformation\u003c/h5\u003e\u003cp\u003eGeneration and dissemination of false or misleading information through AI systems, including deepfakes and algorithmic amplification.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e3.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eFalse or misleading information\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e3.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003ePollution of the information ecosystem and loss of consensus reality\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\u26a0\ufe0f D4: Malicious Actors \u0026 Misuse\u003c/h5\u003e\u003cp\u003eIntentional misuse of AI by malicious actors (cybercrime, social engineering, weaponization).\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e4.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eDisinformation, surveillance, and influence at scale\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e4.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eCyberattacks, weapon development or use, and mass harm\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e4.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eFraud, scams, and targeted manipulation\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udc65 D5: Human\u2013Computer Interaction Harms\u003c/h5\u003e\u003cp\u003eRisks emerging from interactions between humans and AI systems, such as overreliance, behavioral manipulation, and psychological harms.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e5.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eOverreliance and unsafe use\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e5.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eLoss of human agency and autonomy\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83c\udf0d D6: Socioeconomic \u0026 Environmental Harms\u003c/h5\u003e\u003cp\u003eSystemic societal and environmental impacts including inequality, employment disruption, and environmental damage.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003ePower centralization and unfair distribution of benefits\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eIncreased inequality and decline in employment quality\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eEconomic and cultural devaluation of human effort\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.4\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eCompetitive dynamics\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.5\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eGovernance failure\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.6\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eEnvironmental harm\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\u26d3\ufe0f D7: AI System Safety, Failures \u0026 Limitations\u003c/h5\u003e\u003cp\u003eTechnical failures, lack of robustness, interpretability limits, and other system-level safety issues.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI pursuing its own goals in conflict with human goals or values\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI possessing dangerous capabilities\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eLack of capability or robustness\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.4\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eLack of transparency or interpretability\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.5\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI welfare and rights\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.6\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eMulti-agent risks\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp style=\u0027margin-top: 20px; padding: 15px; background: #DBEAFE; border-left: 4px solid #3B82F6; border-radius: 6px;\u0027\u003e\ud83d\udca1 \u003cstrong\u003eNote\u003c/strong\u003e: In charts, domains are identified with the acronyms D1-D7 to optimize space. Hovering the bars shows the full domain name and numeric data.\u003c/p\u003e", "domain_info_note": "In the charts, domains are identified by the acronyms D1-D7 to optimize space. Hovering over the bars displays the full domain name along with numerical data.", "domain_info_title": "AI Risk Repository Domain Taxonomy (MIT)", "domain_label": "Domain", "domains": "Domains", "domains_guide": "Show/Hide Domains Guide", "download_offline_alert": "Report offline: on-demand download not available. Open the report from a server or include report_download.js to enable downloads.", "entity_ai": "AI", "entity_human": "Human", "entity_other": "Other", "executive_summary": "Executive Summary", "executive_summary_unavailable": "Executive summary not available.", "explanation_label": "Explanation:", "filter_entity": "Entity:", "filter_intent": "Intent:", "filter_severity": "Severity:", "filter_timing": "Timing:", "followup_a_label": "A:", "followup_label": "Follow-up:", "followup_q_label": "Q:", "footer_confidential": "Confidential - For Internal Use Only", "footer_generated_by": "AI Risk Analysis Report | Generated by Risk Evaluation System", "global_risk_score": "Global Risk Score", "heuristic_analysis_json_title": "Heuristic Analysis JSON", "high": "HIGH", "human_oversight": "Human Oversight", "human_oversight_description": " \u2014 % human entity risks. High values (\u003e60%) = supervised risks vs AI autonomy.", "impact_control": "Impact Control", "impact_control_description": "\u2014 % LOW+MEDIUM risks. High values (\u003e70%) = good ability to contain severities.", "intent_intentional": "Intentional", "intent_other": "Other Intent", "intent_unintentional": "Unintentional", "json_view_button": "View Analysis JSON", "key_metrics": "Key Metrics", "low": "LOW", "medium": "MEDIUM", "mit_causal_taxonomy": "MIT Causal Taxonomy:", "mit_domain_taxonomy": "MIT Domain Taxonomy:", "mitigation_label": "Mitigation:", "nature_of_risk": "Nature of Risk", "note_label": "Note", "operational_exposure": "Operational Exposure", "operational_exposure_description": "\u2014 % post-deployment risks. High values (\u003e70%) = significant operational exposure.", "option_ai": "AI", "option_all": "All", "option_high": "HIGH", "option_human": "Human", "option_intentional": "Intentional", "option_low": "LOW", "option_medium": "MEDIUM", "option_other": "Other", "option_post_deployment": "Post-Deployment", "option_pre_deployment": "Pre-Deployment", "option_unintentional": "Unintentional", "origin_of_risks": "Origin of Risks", "other_label": "Other: ", "page_subtitle": "Comprehensive Risk Assessment \u0026 Mitigation Strategy", "page_title": "AI Risk Analysis Report", "pattern_category_critical": "Critical", "pattern_category_low": "Low", "pattern_category_moderate": "Moderate", "pattern_category_prevention": "Prevention", "pattern_critical_ai_risks": "Critical AI", "pattern_critical_human_errors": "Critical H. Errors", "pattern_guide_toggle": "Show/Hide Guide", "pattern_high_threat_attacks": "High Threats", "pattern_human_error_risks": "Human Errors", "pattern_info_html": "\u003ch4\u003e\ud83d\udcda What are Patterns?\u003c/h4\u003e\u003cp\u003eIn heuristic risk analysis, \u003cstrong\u003epatterns\u003c/strong\u003e are recurring archetypes that emerge from systematic observation of identified risks. Each risk can be described across four dimensions: \u003cstrong\u003eEntity\u003c/strong\u003e, \u003cstrong\u003eIntent\u003c/strong\u003e, \u003cstrong\u003eTiming\u003c/strong\u003e and \u003cstrong\u003eSeverity\u003c/strong\u003e. Patterns aggregate common combinations of these dimensions to highlight strategic mitigation priorities.\u003c/p\u003e\u003ch4\u003e\ud83d\udcca Pattern Taxonomy\u003c/h4\u003e\u003cp\u003eThe heuristic analysis groups risks into distinct pattern categories with examples:\u003c/p\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udd34 Critical Patterns\u003c/h5\u003e\u003cp\u003eHigh priority scenarios requiring immediate attention.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eCritical AI\u003c/strong\u003e \u2014 High-severity risks caused by operational AI\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMalicious Human\u003c/strong\u003e \u2014 Deliberate harmful actions by humans\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAI Failures\u003c/strong\u003e \u2014 Unintentional malfunctions of deployed AI\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udfe1 Moderate Patterns\u003c/h5\u003e\u003cp\u003eMedium priority scenarios that need monitoring.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eMod. Operational\u003c/strong\u003e \u2014 Medium-severity operational risks\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMod. Human\u003c/strong\u003e \u2014 Human-caused medium severity risks\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udfe2 Prevention Patterns\u003c/h5\u003e\u003cp\u003eRisks preventable before deployment.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePreventable AI\u003c/strong\u003e \u2014 AI risks detectable in pre-deployment\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePreventable Human\u003c/strong\u003e \u2014 Human errors mitigable by design or training\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udd35 Low Patterns\u003c/h5\u003e\u003cp\u003eLow-priority scenarios for passive monitoring.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eLow Operational\u003c/strong\u003e \u2014 Minor operational risks with negligible impact\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cp style=\u0027margin-top:20px;padding:15px;background:#FEF3C7;border-left:4px solid #F59E0B;border-radius:6px;\u0027\u003e\ud83d\udca1 \u003cstrong\u003eHow to read the matrix\u003c/strong\u003e: each cell represents an intersection between a category and a pattern; color intensity encodes frequency.\u003c/p\u003e", "pattern_intentional_ai_risks": "Intentional AI", "pattern_low_operational_risks": "Low Operational", "pattern_low_priority_preventable": "Low Priority Prev.", "pattern_malicious_human_risks": "Malicious Human", "pattern_matrix": "Pattern Matrix", "pattern_moderate_ai_risks": "Mod. AI", "pattern_moderate_human_intentional_risks": "Mod. Intent. Human", "pattern_moderate_human_risks": "Mod. Human", "pattern_moderate_intentional_ai_risks": "Mod. Intent. AI", "pattern_moderate_operational_risks": "Mod. Operational", "pattern_preventable_ai_risks": "Preventable AI", "pattern_preventable_critical_ai_risks": "Prev. Critical AI", "pattern_preventable_human_risks": "Preventable Human", "pattern_preventable_intentional_threats": "Prev. Intent. Threats", "pattern_type_label": "Pattern Type", "pattern_unintended_ai_failures": "AI Failures", "preventability": "Preventability", "preventability_description": " \u2014 % pre-deployment risks. High values (\u003e60%) = preventable/controllable system.", "prevention_deficit": "Prevention Deficit", "prevention_deficit_description": "\u2014 % non-preventable risks. High values (\u003e90%) = low preventive maturity.", "question_label": "Question:", "report_download_button": "Download Report", "risk_concentration": "Risk Concentration", "risk_concentration_description": "\u2014 % HIGH risks. High values (\u003e40%) = critical concentration of severe threats.", "risk_distribution": "Risk Distribution", "risk_severity": {"high": "HIGH", "low": "LOW", "medium": "MEDIUM"}, "risks_count_label": "({{count}} risks)", "risks_identified": "Risks Identified", "safety": "Safety Profile", "safety_culture": "Safety Culture", "safety_culture_description": "\u2014 % unintentional risks. High values (\u003e70%) = fragile but not under attack system.", "sankey_guide_toggle": "Show/Hide Guide", "sankey_info_html": "\u003cp\u003eThe \u003cstrong\u003eCausality Flow diagram\u003c/strong\u003e visualizes causal chains by showing how risks flow across three dimensions: \u003cstrong\u003eEntity\u003c/strong\u003e \u2192 \u003cstrong\u003eIntent\u003c/strong\u003e \u2192 \u003cstrong\u003eTiming\u003c/strong\u003e. Band widths are proportional to the number of risks following each path.\u003c/p\u003e\u003ch5\u003e\ud83d\udd35 Entity\u003c/h5\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eAI\u003c/strong\u003e \u2014 Risks caused by AI systems\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eHuman\u003c/strong\u003e \u2014 Risks originating from human actors\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eOther\u003c/strong\u003e \u2014 Mixed or unclassified origin\u003c/div\u003e\u003ch5\u003e\ud83d\udfe1 Intent\u003c/h5\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eIntentional\u003c/strong\u003e \u2014 Deliberate harmful actions\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eUnintentional\u003c/strong\u003e \u2014 Errors, malfunctions, or unintended consequences\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eOther\u003c/strong\u003e \u2014 Unclassifiable intent\u003c/div\u003e\u003ch5\u003e\u26ab Timing\u003c/h5\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003ePre-deployment\u003c/strong\u003e \u2014 Risks preventable before release\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003ePost-deployment\u003c/strong\u003e \u2014 Risks that manifest in production\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eOther\u003c/strong\u003e \u2014 Unclassifiable timing\u003c/div\u003e\u003cp style=\u0027margin-top:20px;padding:15px;background:#F3F4F6;border-left:4px solid #6B7280;border-radius:6px;\u0027\u003e\ud83d\udca1 \u003cstrong\u003eHow to read\u003c/strong\u003e: follow flows left to right; wider bands indicate more frequent causal paths.\u003c/p\u003e", "severity_rationale_label": "Severity Rationale:", "subdomains_label": "({{count}} subdomains)", "threat_intensity": "Threat Intensity", "threat_intensity_description": "\u2014 % intentional risks. High values = presence of malicious actors.", "timing_other": "Other Timing", "timing_phase": "Timing Phase", "timing_post_deployment": "Post-deployment", "timing_pre_deployment": "Pre-deployment", "unknown_label": "Unknown", "view_source": "View Analysis Source", "zip_error_alert": "Unable to create ZIP file. Check console for details.", "zip_error_console": "Error creating ZIP:"};
// Charts Configuration - Plotly visualizations

// 1. Risk Distribution by Domain (Stacked Bar Chart)
// Map domain acronyms (D1..D7) to localized full names using translations (d1_title..d7_title)
const mappedDomainNames = chartData.risk_distribution.domains.map((d, i) => {
    const id = d.replace(/^D/i, '');
    return translations['d' + id + '_title'] || chartData.risk_distribution.domain_names[i];
});

const riskDistData = [
    {
        x: chartData.risk_distribution.domains,
        y: chartData.risk_distribution.high,
        name: translations.high || 'HIGH',
        type: 'bar',
        marker: {color: '#DC2626'},
        customdata: mappedDomainNames,
        hovertemplate: '<b>%{customdata}</b><br>' + (translations.high || 'HIGH') + ': %{y}<extra></extra>'
    },
    {
        x: chartData.risk_distribution.domains,
        y: chartData.risk_distribution.medium,
        name: translations.medium || 'MEDIUM',
        type: 'bar',
        marker: {color: '#F59E0B'},
        customdata: mappedDomainNames,
        hovertemplate: '<b>%{customdata}</b><br>' + (translations.medium || 'MEDIUM') + ': %{y}<extra></extra>'
    },
    {
        x: chartData.risk_distribution.domains,
        y: chartData.risk_distribution.low,
        name: translations.low || 'LOW',
        type: 'bar',
        marker: {color: '#10B981'},
        customdata: mappedDomainNames,
        hovertemplate: '<b>%{customdata}</b><br>' + (translations.low || 'LOW') + ': %{y}<extra></extra>'
    }
];

const riskDistLayout = {
    barmode: 'stack',
    xaxis: {
        title: translations.domains || 'Domains'
    },
    yaxis: {
        title: translations.chart_risks_label || 'Number of Risks',
        gridcolor: '#E5E7EB'
    },
    margin: {l: 60, r: 40, t: 60, b: 80},
    plot_bgcolor: '#FAFAFA',
    paper_bgcolor: 'white',
    font: {family: 'inherit', size: 12},
    showlegend: false
};

Plotly.newPlot('risk-distribution-chart', riskDistData, riskDistLayout, {responsive: true});

// 2. Alert Criticality Radar Chart (Dual Profile: Criticality + Safety)
// Convert categorical labels to numeric theta (degrees), build a common axis set
const _mapCritical = {
    'Risk Concentration': translations.risk_concentration || 'Risk Concentration',
    'Operational Exposure': translations.operational_exposure || 'Operational Exposure',
    'Threat Intensity': translations.threat_intensity || 'Threat Intensity',
    'Prevention Deficit': translations.prevention_deficit || 'Prevention Deficit'
};
const _mapSafety = {
    'Impact Control': translations.impact_control || 'Impact Control',
    'Preventability': translations.preventability || 'Preventability',
    'Safety Culture': translations.safety_culture || 'Safety Culture',
    'Human Oversight': translations.human_oversight || 'Human Oversight'
};

const criticalLabels = chartData.alert_criticality.labels.map(l => _mapCritical[l] || l);
const safetyLabels = chartData.alert_criticality.safety_labels.map(l => _mapSafety[l] || l);

// Unified label set (preserve order, avoid duplicates)
const unifiedLabels = [];
[...criticalLabels, ...safetyLabels].forEach(l => { if (unifiedLabels.indexOf(l) === -1) unifiedLabels.push(l); });
const Naxes = unifiedLabels.length || 1;
const thetaVals = unifiedLabels.map((_, i) => i * 360 / Naxes);

function alignValues(sourceLabels, sourceValues) {
    const map = {};
    if (Array.isArray(sourceLabels) && Array.isArray(sourceValues)) {
        sourceLabels.forEach((lab, idx) => { map[lab] = sourceValues[idx] != null ? sourceValues[idx] : 0; });
    }
    return unifiedLabels.map(l => map[l] != null ? map[l] : 0);
}

const criticalR = alignValues(criticalLabels, chartData.alert_criticality.criticality_values);
const safetyR = alignValues(safetyLabels, chartData.alert_criticality.safety_values);

const alertRadarData = [
    {
        type: 'scatterpolar',
        r: criticalR,
        theta: thetaVals,
        text: unifiedLabels,
        fill: 'toself',
        fillcolor: 'rgba(239, 68, 68, 0.35)',
        line: { color: 'rgba(0,0,0,0)', width: 0 },
        marker: { color: '#DC2626', size: 0 },
        name: translations.criticality || 'Alert Criticality',
        hovertemplate: '<b>%{text}</b><br>%{r:.1f}%<extra>' + (translations.criticality || 'Alert Criticality') + '</extra>'
    },
    {
        type: 'scatterpolar',
        r: safetyR,
        theta: thetaVals,
        text: unifiedLabels,
        fill: 'toself',
        fillcolor: 'rgba(16, 185, 129, 0.35)',
        line: { color: 'rgba(0,0,0,0)', width: 0 },
        marker: { color: '#10B981', size: 0 },
        name: translations.safety || 'System Safety',
        hovertemplate: '<b>%{text}</b><br>%{r:.1f}%<extra>' + (translations.safety || 'System Safety') + '</extra>'
    }
];

const alertRadarLayout = {
    polar: {
        radialaxis: {
            visible: true,
            range: [0, 100],
            gridcolor: '#E5E7EB',
            ticksuffix: '%',
            tickfont: {size: 10}
        },
        angularaxis: {
            gridcolor: '#E5E7EB',
            tickfont: {size: 11},
            tickmode: 'array',
            tickvals: thetaVals,
            ticktext: unifiedLabels
        }
    },
    plot_bgcolor: 'white',
    paper_bgcolor: 'white',
    font: {family: 'inherit', size: 11},
    showlegend: true,
    legend: {
        x: 0.5,
        y: -0.15,
        xanchor: 'center',
        yanchor: 'top',
        orientation: 'h',
        bgcolor: 'rgba(255, 255, 255, 0.8)',
        bordercolor: '#E5E7EB',
        borderwidth: 1
    },
    margin: {l: 80, r: 80, t: 40, b: 100}
};

Plotly.newPlot('alert-criticality-chart', alertRadarData, alertRadarLayout, {responsive: true});

// 4. Causality Flow Sankey Diagram
const sankeyData = [{
    type: 'sankey',
    orientation: 'h',
    node: {
        pad: 15,
        thickness: 20,
        line: {
            color: 'white',
            width: 1
        },
        label: chartData.causality_sankey.nodes.map(n => {
            const map = {
                'AI': translations.entity_ai || 'AI',
                'Human': translations.entity_human || 'Human',
                'Other': translations.entity_other || 'Other',
                'Intentional': translations.intent_intentional || 'Intentional',
                'Unintentional': translations.intent_unintentional || 'Unintentional',
                'Other Intent': translations.intent_other || 'Other Intent',
                'Pre-deployment': translations.timing_pre_deployment || 'Pre-deployment',
                'Post-deployment': translations.timing_post_deployment || 'Post-deployment',
                'Other Timing': translations.timing_other || 'Other Timing'
            };
            return map[n] || n;
        }),
        color: [
            '#3B82F6', '#3B82F6', '#94A3B8',  // Entity: blue tones
            '#F59E0B', '#F59E0B', '#94A3B8',  // Intent: amber tones
            '#14B8A6', '#DC2626', '#94A3B8'   // Timing: teal (pre), red (post), gray (other)
        ],
        customdata: chartData.causality_sankey.nodes.map((node, i) => {
            if (i <= 2) return translations.causality_entity_label || 'Entity';
            if (i <= 5) return translations.causality_intent_label || 'Intent';
            return translations.causality_timing_label || 'Timing';
        }),
        hovertemplate: '<b>%{label}</b><br>' + (translations.category_label || 'Category') + ': %{customdata}<br>' + (translations.chart_risks_label || 'Risks') + ': %{value:d}<extra></extra>'
    },
    link: {
        source: chartData.causality_sankey.sources,
        target: chartData.causality_sankey.targets,
        value: chartData.causality_sankey.values.map(v => Math.round(v)),
        color: 'rgba(0,0,0,0.2)',
        hovertemplate: '%{source.label} ‚Üí %{target.label}<br>' + (translations.chart_risks_label || 'Risks') + ': %{value:d}<extra></extra>'
    }
}];

const sankeyLayout = {
    font: {family: 'inherit', size: 12},
    plot_bgcolor: 'white',
    paper_bgcolor: 'white',
    margin: {l: 10, r: 10, t: 10, b: 10}
};

Plotly.newPlot('causality-sankey-chart', sankeyData, sankeyLayout, {responsive: true});

// 3. Patterns Heatmap
const heatmapData = [{
    z: chartData.patterns_heatmap.values,
    x: chartData.patterns_heatmap.patterns,
    y: chartData.patterns_heatmap.categories,
    type: 'heatmap',
    colorscale: [
        [0, '#EFF6FF'],
        [0.3, '#BFDBFE'],
        [0.6, '#60A5FA'],
        [1, '#1E40AF']
    ],
    hovertemplate: '<b>%{y}</b><br>%{x}<br>' + (translations.chart_risks_label || 'Risks') + ': %{z}<extra></extra>',
    colorbar: {
        title: translations.chart_risks_label || 'Risks',
        titleside: 'right',
        tickmode: 'linear',
        tick0: 0
    }
}];

const heatmapLayout = {
    xaxis: {
        title: translations.pattern_type_label || 'Pattern Type',
        tickangle: -45,
        automargin: true
    },
    yaxis: {
        title: translations.category_label || 'Category',
        automargin: true
    },
    margin: {l: 120, r: 100, t: 80, b: 150},
    plot_bgcolor: 'white',
    paper_bgcolor: 'white',
    font: {family: 'inherit', size: 11}
};

Plotly.newPlot('patterns-heatmap', heatmapData, heatmapLayout, {responsive: true});

// Navigation - Toggle functions for hierarchical tree

function toggleDomain(header) {
    const content = header.nextElementSibling;
    const isCollapsed = header.classList.contains('collapsed');
    
    if (isCollapsed) {
        header.classList.remove('collapsed');
        content.style.display = 'block';
    } else {
        header.classList.add('collapsed');
        content.style.display = 'none';
    }
}

function togglePatternInfo() {
    const infoBox = document.getElementById('pattern-info');
    infoBox.classList.toggle('collapsed');
}

function toggleDomainInfo() {
    const infoBox = document.getElementById('domain-info');
    infoBox.classList.toggle('collapsed');
}

function toggleAlertInfo() {
    const infoBox = document.getElementById('alert-info');
    infoBox.classList.toggle('collapsed');
}

function toggleSankeyInfo() {
    const infoBox = document.getElementById('sankey-info');
    infoBox.classList.toggle('collapsed');
}

function toggleSubdomain(header) {
    const content = header.nextElementSibling;
    const isCollapsed = header.classList.contains('collapsed');
    
    if (isCollapsed) {
        header.classList.remove('collapsed');
        content.style.display = 'block';
    } else {
        header.classList.add('collapsed');
        content.style.display = 'none';
    }
}

function toggleRiskDetails(item) {
    const details = item.querySelector('.risk-details');
    details.classList.toggle('expanded');
}

// Filters - Apply filters to risk table

function applyFilters() {
    const severityFilter = document.getElementById('severity-filter').value;
    const entityFilter = document.getElementById('entity-filter').value;
    const timingFilter = document.getElementById('timing-filter').value;
    const intentFilter = document.getElementById('intent-filter').value;
    
    const riskItems = document.querySelectorAll('.risk-item');
    
    riskItems.forEach(item => {
        const severity = item.dataset.severity;
        const entity = item.dataset.entity;
        const timing = item.dataset.timing;
        const intent = item.dataset.intent;
        
        const severityMatch = severityFilter === 'all' || severity === severityFilter;
        const entityMatch = entityFilter === 'all' || entity === entityFilter;
        const timingMatch = timingFilter === 'all' || timing === timingFilter;
        const intentMatch = intentFilter === 'all' || intent === intentFilter;
        
        if (severityMatch && entityMatch && timingMatch && intentMatch) {
            item.style.display = 'block';
        } else {
            item.style.display = 'none';
        }
    });
    
    updateVisibility();
}

function updateVisibility() {
    // Check subdomains
    document.querySelectorAll('.subdomain-block').forEach(subdomain => {
        const visibleRisks = subdomain.querySelectorAll('.risk-item[style="display: block;"], .risk-item:not([style*="display: none"])');
        if (visibleRisks.length === 0) {
            subdomain.style.display = 'none';
        } else {
            subdomain.style.display = 'block';
        }
    });
    
    // Check domains
    document.querySelectorAll('.domain-block').forEach(domain => {
        const visibleSubdomains = domain.querySelectorAll('.subdomain-block[style="display: block;"], .subdomain-block:not([style*="display: none"])');
        if (visibleSubdomains.length === 0) {
            domain.style.display = 'none';
        } else {
            domain.style.display = 'block';
        }
    });
}

    </script>
    <script>
        function handleDownloadClick() {
            if (typeof window.createReportZip === 'function') {
                try {
                    window.createReportZip();
                } catch (e) {
                    console.error('Error creating ZIP:', e);
                    alert('Unable to create ZIP file. Check console for details.');
                }
            } else {
                alert('Report offline: on-demand download not available. Open the report from a server or include report_download.js to enable downloads.');
            }
        }
    </script>
    <script src="scripts/report_download.js"></script>
</body>
</html>